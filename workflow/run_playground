import os.path
import sys
sys.path.append(".")

import numpy as np
import yaml
from itertools import product

from molgri.paths import PATH_EXPERIMENTS

rule lowest_e:
    input:
        energy = f"/home/hanaz63/Downloads/ATB_GROMOS/two_molecules_cal/energy.xvg"
    output:
        list_structures = f"/home/hanaz63/Downloads/ATB_GROMOS/two_molecules_cal/structures.txt"
    params:
        num = 4
    run:
        from molgri.space.utils import k_argmin_in_array
        from molgri.io import EnergyReader
        er = EnergyReader(input.energy).load_energy()
        energies2 = er["Coulomb (SR)"]
        energies5 = er["LJ (SR)"]
        energies6 = er["Potential"]
        energies7 = er["Disper. corr."]

        all_lowest_ind = k_argmin_in_array(energies6, k=params.num)
        all_lowest_E = energies6[all_lowest_ind]
        sort_index = np.argsort(all_lowest_E)
        sorted_indices = all_lowest_ind[sort_index]
        print("POTENTIAL")
        print(", ".join([str(x+1) for x in all_lowest_ind]))
        print(all_lowest_E)
        np.savetxt(output.list_structures, sorted_indices)

rule compare_bpti_evec_with_pdb:
    input:
        reference = f"../../../Downloads/4Y0Y_clean.pdb",
        m1 = f"experiments/sqra_bpti_trypsine/example/configA/m1.gro",
        structure = f"experiments/sqra_bpti_trypsine/example/configA/structure.gro",
        trajectory = f"experiments/sqra_bpti_trypsine/example/configA/trajectory.xtc",
    params:
        frames = [2098, 4518, 6603, 6392, 34402]
    output:
        aligned = f"../../../Downloads/aligned.xtc"
    run:
        import MDAnalysis as mda
        from MDAnalysis.analysis import align
        from MDAnalysis.analysis.rms import rmsd

        m1 = mda.Universe(input.m1)
        m1_names = [atom.name for atom in m1.atoms]


        ref = mda.Universe(input.reference)
        mobile = mda.Universe(input.structure, input.trajectory)
        first_few = mobile.select_atoms("protein and name CA and index 0:1008")
        first_few_dynamic = ref.select_atoms("protein and name CA and index 0:1008")

        print(len(ref.atoms), len(mobile.atoms))

        for my_atoms in zip(first_few.atoms, first_few_dynamic.atoms):
            if len(my_atoms) == 2:
                print(my_atoms[0].index, my_atoms[1].index)
        # for res in zip(first_few, first_few_dynamic):
        #     if len(res)==2 and res[0].resid != res[1].resid:
        #         print(res[0], res[1])
        #         break

        alignment = align.AlignTraj(mobile, ref, select="protein and name CA and index 0:1008",filename=output.aligned)

        alignment.run()

# what you wanna adapt:
num_orientations = np.linspace(8,80,10)
num_directions = np.linspace(8,80,10)
radial_distances_nm = [f'linspace(0.2, 0.4, {i})' for i in np.linspace(2, 15, 10, dtype=int)]
grid_identifier = [f"size_{k}" for k in range(len(num_orientations)*len(num_directions)*len(radial_distances_nm))]

grid_options = product(num_orientations, num_directions, radial_distances_nm)

rule prepare_multiple_config_files:
    input:
        initial_config = "input/sqra_water_in_vacuum/all_config_files/default_small_configuration_file.yaml"
    output:
        new_config = expand("input/sqra_water_in_vacuum/all_config_files/{gr_i}.yaml", gr_i=grid_identifier)
    run:
        with open(input.initial_config,'r') as f:
            doc = yaml.safe_load(f)

        for i, out_file in enumerate(output.new_config):
            new_doc = doc.copy()
            current_option = next(grid_options)
            new_doc["params_grid"]["num_orientations"] = int(current_option[0])
            new_doc["params_grid"]["num_directions"] = int(current_option[1])
            new_doc["params_grid"]["radial_distances_nm"] = str(current_option[2])
            new_doc["grid_identifier"] = grid_identifier[i]
            new_doc["experiment_id"] = "size_experiment"
            with open(out_file,"w") as f:
                yaml.dump(new_doc,f)

rule run_one_config_file:
    input:
        config_file="input/sqra_water_in_vacuum/all_config_files/{gr_i}.yaml"
    output:
        done = "input/sqra_water_in_vacuum/all_config_files/finished_{gr_i}.checkpoint"
    resources:
        cores = 1
    shell:
        "snakemake --snakefile workflow/run_sqra --cores {resources.cores} --configfile {input.config_file}  --rerun-incomplete --keep-going > {output.done}"


rule run_multiple_config_files:
    input:
        config_file=expand("input/sqra_water_in_vacuum/all_config_files/finished_{gr_i}.checkpoint",gr_i=grid_identifier)


rule plot_time_its_diff_sizes:
    input:
        time_energy = expand("experiments/sqra_water_in_vacuum/size_experiment/{gr_i}/gromacs_benchmark.txt", gr_i=grid_identifier),
        time_decomposition = expand("experiments/sqra_water_in_vacuum/size_experiment/{gr_i}/decomposition_benchmark.txt",gr_i=grid_identifier),
        params = expand("experiments/sqra_water_in_vacuum/size_experiment/{gr_i}/total_log.yaml", gr_i=grid_identifier),
        itses = expand("experiments/sqra_water_in_vacuum/size_experiment/{gr_i}/its.csv", gr_i=grid_identifier),
    output:
        csv_file = "experiments/sqra_water_in_vacuum/size_experiment/size_analysis.csv",
        its_plot = "experiments/sqra_water_in_vacuum/size_experiment/size_its_analysis.png"
    params:
        num_its = 5
    run:
        # todo show time of calclation
        # todo: also show some eigenvectors
        from molgri.io import BenchmarkReader, ParameterReader, ItsReader
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns
        import matplotlib.gridspec as gridspec

        data = []
        for t_e, t_d, my_params, its in zip(input.time_energy, input.time_decomposition, input.params, input.itses):
            time_gromacs = BenchmarkReader(t_e).get_mean_time_in_s()
            time_decomp = BenchmarkReader(t_d).get_mean_time_in_s()
            all_params = ParameterReader(my_params).get_grid_size_params_als_dict()
            its_num = ItsReader(its).get_first_N_its(params.num_its)
            size_data = [time_gromacs, time_decomp, *all_params, *its_num]
            data.append(size_data)


        columns = ["Time gromacs [s]", "Time decomposition [s]", "Num. directions", "Num. orientations", "Num. radii"]
        columns.extend([f"ITS {i+1} [ps]" for i in range(params.num_its)])
        df = pd.DataFrame(data, columns=columns)
        df["Total time [min]"] = (df["Time gromacs [s]"]+df["Time decomposition [s]"])/60
        df["Total num gridpoints"] = df["Num. directions"]*df["Num. orientations"]*df["Num. radii"]
        df.to_csv(output.csv_file)

        fig = plt.figure(figsize=(8, 12))  # Adjust figure size to your needs
        gs = gridspec.GridSpec(4,3,width_ratios=[1, 1, 1])
        ax1 = fig.add_subplot(gs[0, :])
        ax1_bigger = fig.add_subplot(gs[1, :])
        ax2 = fig.add_subplot(gs[2, 0])
        ax3 = fig.add_subplot(gs[2, 1])
        ax4 = fig.add_subplot(gs[2, 2])
        ax5 = fig.add_subplot(gs[3, 0])
        ax6 = fig.add_subplot(gs[3, 1])
        ax7 = fig.add_subplot(gs[3, 2])

        colors = [plt.cm.tab20(i) for i in range(20)]

        ax1_twin = ax1.twinx()
        sns.lineplot(df,x="Total num gridpoints",y="Total time [min]",ax=ax1_twin,color="black", linestyle="--")
        for i in range(params.num_its):
            sns.lineplot(df,x="Total num gridpoints",y=f"ITS {i + 1} [ps]",ax=ax1,color=colors[i],marker="o", markersize=5)
            sns.lineplot(df,x="Total num gridpoints",y=f"ITS {i + 1} [ps]",ax=ax1_bigger,color=colors[i],marker="o",markersize=5)
            sns.lineplot(df, x="Num. directions", y=f"ITS {i+1} [ps]", ax=ax2, color=colors[i], marker="o", markersize=5)
            sns.lineplot(df,x="Num. orientations",y=f"ITS {i + 1} [ps]",ax=ax3, color=colors[i], marker="o", markersize=5)
            sns.lineplot(df,x="Num. radii",y=f"ITS {i + 1} [ps]",ax=ax4, color=colors[i], marker="o", markersize=5)
            sns.lineplot(df, x="Num. directions", y=f"ITS {i+1} [ps]", ax=ax5, color=colors[i], marker="o", markersize=5)
            sns.lineplot(df,x="Num. orientations",y=f"ITS {i + 1} [ps]",ax=ax6, color=colors[i], marker="o", markersize=5)
            sns.lineplot(df,x="Num. radii",y=f"ITS {i + 1} [ps]",ax=ax7, color=colors[i], marker="o", markersize=5)


        ax1.set(ylabel="ITS [ps]", yscale="log") #, xscale="log" ,
        ax1_bigger.set(ylabel="ITS [ps]",ylim=(0,100))  #, xscale="log" ,
        ax2.set(ylabel="ITS [ps]")
        ax3.set(ylabel="ITS [ps]")
        ax4.set(ylabel="ITS [ps]")
        ax5.set(ylabel="ITS [ps]", ylim=(0,100))
        ax6.set(ylabel="ITS [ps]", ylim=(0,100))
        ax7.set(ylabel="ITS [ps]", ylim=(0,100))


        fig.tight_layout()
        fig.savefig(output.its_plot)

#"experiments/guanidinium_xyz/example/medium_gua_grid/"
# "experiments/water_xyz/example/large_example_water/"
EXPERIMENT_FULL_PATH = "experiments/water_xyz/example_new/water_64K/SP_PBE0_def2tzvp_water_D4/"
NUM_GRID_POINTS = 64000
index1 = 3
type_run = "water_xyz"

rule run_clustering_labelling:
    input:
        eigenvectors = f"{EXPERIMENT_FULL_PATH}eigenvectors.npy",
    params:
        num_clusters = 12
    output:
        labels = f"{EXPERIMENT_FULL_PATH}labels.npy"
    run:
        from sklearn.cluster import KMeans

        eigenvectors = np.load(input.eigenvectors)[:, :6]
        clustering = KMeans(n_clusters=params.num_clusters).fit(eigenvectors)
        my_labels = clustering.labels_
        unique, counts = np.unique(my_labels, return_counts=True)
        print(unique[np.where(counts>10)[0]], counts[np.where(counts>10)[0]])
        np.save(output.labels, my_labels)


rule run_clustering_plotting:
    input:
        structure = f"{EXPERIMENT_FULL_PATH}structure.xyz",
        trajectory =  f"{EXPERIMENT_FULL_PATH}trajectory.xyz",
        labels = f"{EXPERIMENT_FULL_PATH}labels.npy",
        eigenvectors = f"{EXPERIMENT_FULL_PATH}eigenvectors.npy",
        script= "molgri/scripts/vmd_position_sqra_water"
    output:
        plot = f"{EXPERIMENT_FULL_PATH}clustering.png",
        clustering_vmdlog = f"{EXPERIMENT_FULL_PATH}clustering_vmdlog",
        vmd_plot_tga = f"{EXPERIMENT_FULL_PATH}eigenvector_clustering.tga",
        #vmd_plot_png = f"{EXPERIMENT_FULL_PATH}eigenvector_clustering.png",
    run:

        eigenvectors = np.load(input.eigenvectors)[:,:6]

        import matplotlib.pyplot as plt
        import seaborn as sns
        from molgri.plotting.create_vmdlog import VMDCreator

        sns.set_style("white")
        fig, ax = plt.subplots(1,1,subplot_kw={"projection": "3d"})
        c = np.load(input.labels).astype(int)

        palette_sqra = ["yellow", "orange", "green", "blue", "cyan", "purple", "gray", "pink", "red", "magenta"]  #pop over 10
        #palette = ["black", "yellow", "orange", "green", "blue", "cyan", "purple", "gray", "pink", "red"]   # pop over 20


        first_evec = eigenvectors.T[1]
        second_evec = eigenvectors.T[2]
        third_evec = eigenvectors.T[3]
        unique, counts = np.unique(c,return_counts=True)
        #print(unique, counts)
        list_of_indices = []
        list_of_palette = []
        color_index = 0
        for i, label in enumerate(unique[np.where(counts>1)[0]]):
            cluster = np.where(c == label)[0]
            population = len(cluster)

            if population > 50 and population < 200:
                list_of_indices.append([x + 1 for x in np.random.choice(cluster,30)])
                ax.scatter(first_evec[cluster],second_evec[cluster],third_evec[cluster],c=[palette_sqra[color_index], ] * len(cluster))
                color_index += 1
                #list_of_palette.append(palette_sqra[i])
            elif population >7 and population <= 50:
                list_of_indices.append([x + 1 for x in cluster])
                ax.scatter(first_evec[cluster],second_evec[cluster],third_evec[cluster],c=[palette_sqra[color_index], ] * len(cluster))
                color_index += 1
                #list_of_palette.append(palette_sqra[i])
        print([len(i) for i in list_of_indices])


        plt.savefig(output.plot, dpi=600)
        print(list_of_indices)
        vmd_creator = VMDCreator(index_first_molecule=f"index < {index1}",index_second_molecule=f"index >= {index1}",
            is_protein=False)
        vmd_creator.load_translation_rotation_script(input.script)

        individual_names = [f"{os.path.split(output.vmd_plot_tga)[0]}/cluster_{i}.tga" for i in range(len(list_of_indices))]
        vmd_creator.prepare_clustering_script(list_of_indices,palette_sqra[:len(list_of_indices)], output.vmd_plot_tga, individual_names)
        vmd_creator.write_text_to_file(output.clustering_vmdlog)


        # TODO: if trajectory in a directory, you can load structure trajectory/*
        shell("vmd  -dispdev text {input.structure} {input.trajectory} < {output.clustering_vmdlog}")
        #for el_tga, el_png in zip(output.vmd_plot_tga, output.vmd_plot_png):
        #    shell("convert {el_tga} {el_png}")


GRID_DIR = "experiments/grids/large_example_water/"
PATH_SEARCH_DIR = "experiments/water_xyz/example/large_example_water/"
PATH_START = 21714
PATH_END = 28547

rule run_path_search:
    input:
        adjacency_matrix = f"{GRID_DIR}adjacency_array.npz",
        energy = f"{PATH_SEARCH_DIR}energy.csv"
    output:
        path_plot = f"{PATH_SEARCH_DIR}path_{PATH_START}_{PATH_END}/best_path.png",
        path = f"{PATH_SEARCH_DIR}path_{PATH_START}_{PATH_END}/path.npy"
    run:
        from molgri.space.mazes import Maze
        from scipy.sparse import load_npz
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns

        sns.set_context("talk")
        sns.set_style("white")

        adj = load_npz(input.adjacency_matrix)
        energy = pd.read_csv(input.energy, usecols=["Energy [kJ/mol]"]).to_numpy()

        my_maze = Maze(adj)
        my_maze.add_energy_attribute("Energy [kJ/mol]", energy)

        simple_path =my_maze.smallest_dE_start_path(PATH_START, PATH_END)
        np.save(output.path, simple_path)

        fig, ax = plt.subplots(1,1)
        my_maze.plot_profile_along_path(simple_path, fig, ax)
        sns.despine()
        plt.tight_layout()
        fig.savefig(output.path_plot)

rule vmd_plot_path:
    input:
        path = f"{PATH_SEARCH_DIR}path_{PATH_START}_{PATH_END}/path.npy",
        structure = f"{PATH_SEARCH_DIR}structure.xyz",
        trajectory = f"{PATH_SEARCH_DIR}trajectory.xyz",
        script_rot_tr = f"molgri/scripts/vmd_position_sqra_water"
    output:
        vmdlog = f"{PATH_SEARCH_DIR}path_{PATH_START}_{PATH_END}/path_vmdlog",
        path_video = f"{PATH_SEARCH_DIR}path_{PATH_START}_{PATH_END}/path.mp4"
    run:
        from molgri.plotting.create_vmdlog import VMDCreator

        num_first_mol = 3
        index_first = f"index < {num_first_mol}"
        index_second = f"index >= {num_first_mol}"
        experiment_type="water_xyz"


        vmdlog = VMDCreator(index_first, index_second)
        simple_path = np.load(input.path)
        simple_path_added_one = [sp+1 for sp in simple_path]
        path_names = [f"{PATH_SEARCH_DIR}path_{PATH_START}_{PATH_END}/path_{i}.tga" for i in range(len(simple_path))]

        vmdlog.load_translation_rotation_script(input.script_rot_tr)
        vmdlog.plot_these_structures(simple_path_added_one, path_names)
        vmdlog.write_text_to_file(output.vmdlog)

        shell("vmd -dispdev text {input.structure} {input.trajectory} < {output.vmdlog}")

        tga_str = f"{PATH_SEARCH_DIR}path_{PATH_START}_{PATH_END}/path_*.tga"
        shell("convert -delay 40 -loop 0 {tga_str} {output.path_video}")

#/home/hanaz63/2024_molgri2/nobackup/molecularRotationalGrids/experiments/guanidinium_xyz/example/huge_gua_grid//


EXPERIMENT_FULL_PATH = "experiments/water_xyz/example_new/water_64K/"
rule compare_initial_and_const_opt_energies:
    input:
        initial_energies = f"{EXPERIMENT_FULL_PATH}SP_PBE0_def2tzvp_water_D4/energy.csv",
        const_opt_energies = f"{EXPERIMENT_FULL_PATH}ConstOpt_PBE0_def2tzvp_water_D4/energy.csv"
    output:
        plot = f"{EXPERIMENT_FULL_PATH}absolute_energy_comparison.png",
        #plot_hist = f"{EXPERIMENT_FULL_PATH}energy_hist.png",
        plot_relative = f"{EXPERIMENT_FULL_PATH}relative_energy_comparison.png",
    run:
        import seaborn as sns
        import pandas as pd
        import matplotlib.pyplot as plt

        sns.set_context("talk")

        df_inital = pd.read_csv(input.initial_energies)
        df_const_opt = pd.read_csv(input.const_opt_energies)

        # sp energy
        fig, ax = plt.subplots(1,2, sharey=True, sharex=True)

        kj_mol_water_monomer = -200563.91397680662
        df_inital["Binding energy [kJ/mol]"] = df_inital["Energy [kJ/mol]"]-2*kj_mol_water_monomer
        df_const_opt["Binding energy [kJ/mol]"] = df_const_opt["Energy [kJ/mol]"] - 2 * kj_mol_water_monomer

        filtered_initial = df_inital[df_inital['Binding energy [kJ/mol]'] < 50]
        filtered_const_opt = df_const_opt[df_inital['Binding energy [kJ/mol]'] < 50]


        # sns.histplot(filtered_initial["Binding energy [kJ/mol]"],ax=ax[0], bins=100)
        # ax[0].set_title(f"SP Plotted: {len(filtered_initial)}, not: {len(df_inital)-len(filtered_initial)}")
        # sns.histplot(filtered_const_opt["Binding energy [kJ/mol]"],ax=ax[1], bins=100)
        # ax[1].set_title(f"OPT Plotted: {len(filtered_const_opt)}, not: {len(df_const_opt) - len(filtered_const_opt)}")
        # fig.savefig(output.plot_hist)


        # absolute errors
        fig, ax = plt.subplots(1, 1, figsize=(6,6))

        sns.histplot(df_const_opt['Energy [kJ/mol]']-df_inital['Energy [kJ/mol]'], ax=ax, bins=50, binrange=(-5,1), binwidth=6/50, stat="probability")
        ax.set_xlim(-5, 1)
        ax.set_xlabel("E(opt) - E(SP) [kJ/mol]")
        fig.tight_layout()
        fig.savefig(output.plot)

        # relative errors

        # absolute errors
        fig, ax = plt.subplots(1, 1)

        sns.histplot(100*(filtered_const_opt["Binding energy [kJ/mol]"]-filtered_initial["Binding energy [kJ/mol]"])/np.abs(filtered_const_opt["Binding energy [kJ/mol]"]),
            ax=ax, bins=50, binrange=(-50,0), binwidth=50/50)
        ax.set_xlim(-50,0)
        ax.set_xlabel("Change in energy after optimization [%]")
        fig.tight_layout()
        fig.savefig(output.plot_relative)


# do this only for selected xyz files, eg those in final pics
PLACE = """experiments/water_xyz/example/mid_example_water/ConstOpt_PBE0_def2tzvp_water_D4/"""

rule fill_in_missing_values:
    input:
        const_opt = f"experiments/water_xyz/example_new/water_64K/ConstOpt_PBE0_def2tzvp_water_D4/energy.csv",
        sp = f"experiments/water_xyz/example_new/water_64K/SP_PBE0_def2tzvp_water_D4/energy.csv",
    output:
        filled_in = f"experiments/water_xyz/example_new/water_64K/ConstOpt_PBE0_def2tzvp_water_D4/energy_corr.csv",
        filled_in2= f"experiments/water_xyz/example_new/water_64K/SP_PBE0_def2tzvp_water_D4/energy_corr.csv",
    run:
        import pandas as pd
        df_co = pd.read_csv(input.const_opt)
        df_sp = pd.read_csv(input.sp)


        num_missing = df_co['Energy [kJ/mol]'].isna().sum()
        num_total = len(df_co)
        print(f"Have to fill in {num_missing}/{num_total} missing values ({num_missing/num_total*100})%")

        df_co["Energy [kJ/mol]"] = df_co["Energy [kJ/mol]"].fillna(df_sp["Energy [kJ/mol]"])
        df_co.to_csv(output.filled_in)
        df_sp.to_csv(output.filled_in2)


rule find_missing_values:
    input:
        const_opt= "experiments/water_xyz/example_new/water_64K/ConstOpt_PBE0_def2tzvp_water_D4/energy.csv"
    output:
        list_of_files = "experiments/water_xyz/example_new/water_64K/ConstOpt_PBE0_def2tzvp_water_D4/missing_files.txt"
    run:
        import pandas as pd
        my_df = pd.read_csv(input.const_opt)
        pd.options.display.max_colwidth = 150
        not_finished_df = my_df[~my_df["Normal Finish"]]
        indices = not_finished_df["Frame"].to_numpy()
        files = find_all_structures_with_indices(indices, "experiments/water_xyz/example_new/water_64K/ConstOpt_PBE0_def2tzvp_water_D4/", "orca.inp")
        print(files)
        with open(output.list_of_files, "w") as f:
            f.write("\n".join(files))

rule get_total_time:
    input:
        "experiments/water_xyz/example_new/water_64K/ConstOpt_PBE0_def2tzvp_water_D4/orca_time.txt",
        "experiments/water_xyz/example_new/water_64K/SP_PBE0_def2tzvp_water_D4/orca_time.txt"

rule orca_total_and_average_time:
    input:
        energy=f"{{where}}energy.csv"
    output:
        total_time=f"{{where}}orca_time.txt"
    run:
        import pandas as pd

        my_df = pd.read_csv(input.energy)
        my_df["TIME"] = pd.to_timedelta(my_df["Time [h:m:s]"],errors="coerce")
        my_df["Time [s]"] = my_df["TIME"].dt.total_seconds()
        time_s = my_df["Time [s]"]

        with open(output.total_time,"w") as f:
            f.write(f"Total time [s]: {time_s.sum():.2f}\n")
            f.write(f"Total time [h:m:s]: {pd.to_timedelta(time_s.sum(),unit='s')}\n")
            f.write(f"700 parallel processes total time [h:m:s]: {pd.to_timedelta(time_s.sum()/700,unit='s')}\n")
            f.write("--------------\n")
            f.write(f"Mean time [s]: {time_s.mean():.2f} +- {time_s.std():.2f}\n")
            f.write(f"Mean time [h:m:s]: {pd.to_timedelta(time_s.mean(),unit='s')} +- {pd.to_timedelta(time_s.std(),unit='s')}\n")
            f.write("--------------\n")
            f.write(f"Max time [s]: {time_s.max():.2f}\n")
            f.write(f"Min time [s]: {time_s.min():.2f}\n")
            f.write(f"Max time [h:m:s]: {pd.to_timedelta(time_s.max(),unit='s')}\n")
            f.write(f"Min time [h:m:s]: {pd.to_timedelta(time_s.min(),unit='s')}\n")

rule run_example:
    input:
        "/home/hanaz63/2024_molgri2/nobackup/molecularRotationalGrids/experiments/sqra_water_in_vacuum/example/large_example_water/neighbours_17/vmdlog"



rule plot_neighbours:
    input:
        neighbours_of = "{path}/neighbours_{central_index}/neighbours.txt",
        water_script = "molgri/scripts/vmd_position_sqra_water",
        structure = "{path}/structure.gro",
        trajectory = "{path}/trajectory.xtc"
    output:
        vmdlog="{path}/neighbours_{central_index}/vmdlog",
    run:
        from molgri.plotting.create_vmdlog import VMDCreator

        neighbours = np.loadtxt(input.neighbours_of, dtype=int)
        point_itself = int(wildcards.central_index)

        # a list of the point and its neighbours with +1 for each point -> because VMD starts with 1
        neighbour_list = list(neighbours)
        neighbour_list.append(point_itself)
        neighbour_list = [el+1 for el in neighbour_list]
        neighbour_names = [f"{wildcards.path}/neighbours_{wildcards.central_index}/structure_{i-1}.tga" for i in neighbour_list]
        neighbour_names_png = [f"{wildcards.path}/neighbours_{wildcards.central_index}/structure_{i - 1}.png" for i in neighbour_list]

        num_first_mol = 3
        index_first = f"index < {num_first_mol}"
        index_second = f"index >= {num_first_mol}"
        my_vmd = VMDCreator(index_first, index_second)
        my_vmd.load_translation_rotation_script(input.water_script)
        my_vmd.plot_these_structures(neighbour_list, neighbour_names)
        my_vmd.write_text_to_file(output.vmdlog)

        shell("vmd  -dispdev text {input.structure} {input.trajectory} < {output.vmdlog}")
        for el_tga, el_png in zip(neighbour_names, neighbour_names_png):
            shell("convert {el_tga} {el_png}")

        print(neighbour_list)