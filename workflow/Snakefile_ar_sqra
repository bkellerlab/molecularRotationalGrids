"""
All of the workflows relating to production of trajectories, subsequent MSMs and their related outputs (figures ...)
"""
from time import time
from typing import Any, Tuple, Sequence

import numpy as np

# add molgri directory
import sys
sys.path.append(".")

from molgri.paths import PATH_OUTPUT_AUTOSAVE, PATH_INPUT_BASEGRO, PATH_EXPERIMENTS
from workflow.snakemake_utils import find_config_parameter_value, log_the_run, modify_mdrun, modify_topology, \
    read_from_mdrun
from molgri.constants import TAUS


include: "Snakefile_grids"

#wildcard_constraints:
#    unique_id=".*msm.*"

I_TO_ASSIGN = np.arange(20, 40, dtype=int)

rule all:
    input:
       # "experiments/sqra_helium_10/small_ideal/trajectory"
       #expand(f"experiments/sqra_helium_10/small_ideal/trajectory/solvated_{{i}}.gro", i=np.arange(10, dtype=int)),
       expand(f"experiments/sqra_helium_10/small_ideal/energy/energy_{{i}}.xvg", i=np.arange(10, dtype=int))
       # expand(f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
       #     unique_id=["FAKE4_argon2_cc1_1", "FAKE4_argon2_cc1_10"],
       #     grid_identifier=["80_80_very_short"],
       #     i=np.arange(20, dtype=int)
       # ),
       #  msm_all1 = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its_{{is_corrected}}_{{sigma}}_{{which}}.png",
       #     unique_id=["FAKE2_argon2_cc1_1"], tau=TAUS,
       #     grid_identifier=["80_80_very_short"], sigma=None, which="LR", is_corrected = ["msm"]),
       #  msm_all2 = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}_{{sigma}}_{{which}}_{{is_corrected}}.png",i=[0, 1, 2, 3, 4],
       #     unique_id=["FAKE2_argon2_cc1_1"],
       #     grid_identifier=["80_80_very_short"], sigma=None, which="LR",
       #     tau=[5, 10], suffix=[".png", "_vmdlog_msm"], is_corrected = ["msm"]),
       #  msm_all3=expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}.png",
       #     unique_id=["FAKE2_argon2_cc1_1"],
       #     grid_identifier=["80_80_very_short"],sigma="None",which="LR",
       #     tau=[5, 10],suffix=[".png", "_vmdlog_msm"],is_corrected=["msm"])


rule create_config_file_in_argon:
    """
    The point here is to get the unique ID of the experiment, read all of its parameters from a database of experiments 
    and write them to a file within this experiment folder.
    """
    input:
        experiments_database = "workflow/experiments_in_ar.csv"
    output:
        config_file = f"{PATH_EXPERIMENTS}{{unique_id}}/experiment_config.txt"
    run:
        # read in all parameters
        import pandas as pd
        experiments = pd.read_csv(input.experiments_database, index_col=0)
        columns = experiments.columns
        with open(output.config_file, "w") as f:
            print(experiments, wildcards.unique_id)
            for i, parameter_value in enumerate(experiments.loc[wildcards.unique_id]):
                f.write(f"{columns[i]}={parameter_value}\n")


rule prepare_water_water_in_argon:
    """
    Start with an end structure of a shorter run to have a good starting structure.
    """
    input:
        water_gro = f"{PATH_INPUT_BASEGRO}H2O.gro",
        he_gro= f"{PATH_INPUT_BASEGRO}one_he.gro",
        forcefield1 = f"{PATH_INPUT_BASEGRO}argon_forcefield.itp",
        forcefield2 = f"{PATH_INPUT_BASEGRO}ffnonbonded.itp",
        forcefield3 = f"{PATH_INPUT_BASEGRO}ffbonded.itp",
        water_in_arg_top = f"{PATH_INPUT_BASEGRO}topol_fake_ar_sqra.top",
        water_top= f"{PATH_INPUT_BASEGRO}H2O_H2Op.top",
        base_mdp_file = f"{PATH_INPUT_BASEGRO}mdrun.mdp",
        select_group=f"{PATH_INPUT_BASEGRO}select_group_zero",
        select_centers=f"{PATH_INPUT_BASEGRO}select_3_and_0",
        index_m1=f"{PATH_INPUT_BASEGRO}index_first_mol.ndx",
        select_two=f"{PATH_INPUT_BASEGRO}select_2",
        select_energy=f"{PATH_INPUT_BASEGRO}select_energy_five",
        config_file = f"{PATH_EXPERIMENTS}{{unique_id}}/experiment_config.txt"
    output:
        molecule1=f"{PATH_EXPERIMENTS}{{unique_id}}/m1.gro",
        molecule2=f"{PATH_EXPERIMENTS}{{unique_id}}/m2.gro",
        he_gro=f"{PATH_EXPERIMENTS}{{unique_id}}/one_he.gro",
        select_two= f"{PATH_EXPERIMENTS}{{unique_id}}/select_two",
        forcefield1=f"{PATH_EXPERIMENTS}{{unique_id}}/argon_forcefield.itp",
        forcefield2=f"{PATH_EXPERIMENTS}{{unique_id}}/ffnonbonded.itp",
        forcefield3=f"{PATH_EXPERIMENTS}{{unique_id}}/ffbonded.itp",
        runfile = f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{unique_id}}/topology.top",
        water_top= f"{PATH_EXPERIMENTS}{{unique_id}}/H2O_H2Op.top",
        select_energy= f"{PATH_EXPERIMENTS}{{unique_id}}/select_energy",
        select_group = f"{PATH_EXPERIMENTS}{{unique_id}}/select_group",
        select_centers = f"{PATH_EXPERIMENTS}{{unique_id}}/select_centers",
        index_m1 = f"{PATH_EXPERIMENTS}{{unique_id}}/index_m1.ndx",
    run:
        import shutil
        # stuff that can be copied without being modified
        shutil.copy(input.select_group, output.select_group)
        shutil.copy(input.select_centers,output.select_centers)
        shutil.copy(input.select_energy,output.select_energy)
        shutil.copy(input.water_gro,output.molecule1)
        shutil.copy(input.he_gro,output.he_gro)
        shutil.copy(input.water_gro,output.molecule2)
        shutil.copy(input.forcefield1,output.forcefield1)
        shutil.copy(input.forcefield2,output.forcefield2)
        shutil.copy(input.forcefield3,output.forcefield3)
        shutil.copy(input.select_two,output.select_two)
        shutil.copy(input.index_m1,output.index_m1)

        # depending on config parameters, topology and runfile will be adapted
        shutil.copy(input.water_in_arg_top, output.topology)
        shutil.copy(input.water_top,output.water_top)
        shutil.copy(input.base_mdp_file, output.runfile)

        # modify runfile with given parameters
        trajectory_len = find_config_parameter_value(input.config_file,"traj_len")
        integrator = find_config_parameter_value(input.config_file,"integrator")
        coupling = find_config_parameter_value(input.config_file,"coupling_constant_ps")
        step = find_config_parameter_value(input.config_file, "step_in_ps")
        dielectric_constant = find_config_parameter_value(input.config_file,"epsilon-r")
        modify_mdrun(output.runfile, "integrator", integrator)
        modify_mdrun(output.runfile,"nsteps",trajectory_len)
        modify_mdrun(output.runfile, "compressed-x-grps", "SOLp")
        modify_mdrun(output.runfile,"nstxout-compressed","5")
        modify_mdrun(output.runfile,"coulombtype","PME")
        modify_mdrun(output.runfile,"dt",step)
        modify_mdrun(output.runfile,"pcoupl","no")
        modify_mdrun(output.runfile, "nstxout", "0")
        modify_mdrun(output.runfile,"nstenergy","0")
        modify_mdrun(output.runfile,"epsilon-r",dielectric_constant)

        # two reference groups
        modify_mdrun(output.runfile, "tc-grps", "System")
        modify_mdrun(output.runfile,"ref_t", "300")
        modify_mdrun(output.runfile,"tau_t", f"{coupling}")
        modify_mdrun(output.runfile,"verlet-buffer-tolerance","1e-03")

        # modify topology with given parameters
        up1_nm = find_config_parameter_value(input.config_file,"up1_nm")
        up2_nm = find_config_parameter_value(input.config_file,"up2_nm")
        force = find_config_parameter_value(input.config_file,"force")
        modify_topology(output.topology,i="1",j="4",funct=10,low=0.0,up1=up1_nm,up2=up2_nm,force_constant=force)

rule run_pt:
    """
    This rule should produce the .gro and .xtc files of the pseudotrajectory.
    """
    input:
        molecule1 = f"{PATH_EXPERIMENTS}{{unique_id}}/m1.gro",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.gro",
        grid = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_full_array.npy",
    output:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/structure.gro",
        trajectory_dict = directory(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/trajectory")
    params:
        cell_size_A = 36  # cubic box will be the output, this is size of the box in one dimension
    run:
        from molgri.molecules.writers import PtWriter
        from molgri.molecules.pts import Pseudotrajectory
        from molgri.molecules.parsers import FileParser

        # load grid and molecules
        my_grid = np.load(input.grid)
        my_molecule1 = FileParser(input.molecule1).as_parsed_molecule()
        my_molecule2 = FileParser(input.molecule2).as_parsed_molecule()

        # create PT
        my_pt = Pseudotrajectory(my_molecule2,my_grid)

        # write out .gro and .xtc files
        my_writer = PtWriter("",my_molecule1, (params.cell_size_A, params.cell_size_A, params.cell_size_A, 90, 90, 90))
        my_writer.write_frames_in_directory(my_pt,path_structure=output.structure,path_trajectory=output.trajectory_dict + ".gro")

rule run_solvate_pt:
    """
    Brute-force add lines with solvent
    """
    input:
        trajectory= f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_id}}/trajectory/{{i}}.gro",
        solvent=f"{PATH_EXPERIMENTS}{{unique_id}}/one_he.gro"
    shadow: "shallow"
    output:
        trajectory= f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_id}}/trajectory/solvated_{{i}}.gro",
    shell:
        """
        #!/bin/bash
        export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
        gmx22 solvate -cp {input.trajectory} -cs {input.solvent} -o {output.trajectory} -maxsol 2033
        """

rule run_minimize_pt:
    """
    This rule gets structure, trajectory, topology and gromacs run file as input, as output we are only interested in 
    energies.
    """
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_id}}/trajectory/solvated_{{i}}.gro",
        runfile=f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
        topology=f"{PATH_EXPERIMENTS}{{unique_id}}/topology.top",
        select_two= f"{PATH_EXPERIMENTS}{{unique_id}}/select_two",
        select_energy= f"{PATH_EXPERIMENTS}{{unique_id}}/select_energy"
    shadow: "shallow"
    log:
         log = "experiments/{unique_id}/{grid_id}/logging_gromacs_{i}.log"
    output:
        temp= f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_id}}/trajectory/solvated_{{i}}.trr",
        energy= f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_id}}/energy/energy_{{i}}.xvg"
    shell:
        """
        #!/bin/bash
        export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
        gmx22 grompp -f {input.runfile} -o result.tpr -c {input.structure} -p {input.topology}
        gmx22 mdrun -s result.tpr -x {output.temp} -e ener.edr -g {log.log}  -nt 1
        gmx22 energy -f ener.edr -o {output.energy} < {input.select_energy}
        """


rule run_trajectory_assignment:
    """
    A step before MSM - assign every frame of the trajectory to the corresponding cell

    As input we need the trajectory, structure and full array of the grid we wanna assign to.

    As output we get a cell index for every frame of the trajectory.
    """

    input:
        full_array = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_full_array.npy",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory_slice_{{i}}.xtc",
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.gro",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.gro",
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    threads: 5
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignment_benchmark_{{i}}.txt"
    output:
        partial_assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments_{{i}}.npy",
    run:
        from molgri.molecules.transitions import AssignmentTool

        # using all inputs
        my_grid = np.load(input.full_array)

        # frequency = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        # n_steps = int(read_from_mdrun(input.runfile,"nsteps"))
        # num_frames = n_steps//frequency
        # breakdown = np.linspace(0, num_frames, 20, dtype=int)
        # start = breakdown[int(wildcards.i)]
        # stop = breakdown[int(wildcards.i)+1]

        at = AssignmentTool(my_grid,input.structure,input.trajectory, input.molecule2, n_jobs=1)

        # saving output
        np.save(output.partial_assignments,at.get_full_assignments())
        print(f"Done assignments {wildcards.i}")

rule combine_trajectory_assignment:
    """
    A step before MSM - assign every frame of the trajectory to the corresponding cell

    As input we need the trajectory, structure and full array of the grid we wanna assign to.

    As output we get a cell index for every frame of the trajectory.
    """
    input:
        part_assignments = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments_{{i}}.npy", i=I_TO_ASSIGN, allow_missing=True)
    output:
        assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments_combined.npy",
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/combine_assignment_benchmark.txt"
    run:
        all_assignments = []
        for one_assignment_file in input.part_assignments:
            all_assignments.append(np.load(one_assignment_file))
        # saving output
        all_assignments = np.concatenate(all_assignments)
        print(all_assignments.shape)
        np.save(output.assignments, all_assignments)


rule crop_out_outside_R:
    input:
        #rmsds_mol1 = f"{PATH_EXPERIMENTS}{{unique_id}}/rmsd_mol1.xvg",
        rmsds_mol2 = f"{PATH_EXPERIMENTS}{{unique_id}}/rmsd_mol2.xvg"
    output:
        indices_cropped=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/indices_cropped.npy",
    run:
        from molgri.molecules.parsers import XVGParser
        import pandas as pd

        #radii_1 = XVGParser(input.rmsds_mol1).all_values[:, 1].T
        radii_2 = XVGParser(input.rmsds_mol2).all_values[:, 1].T
        radii = 10 * radii_2

        indices_cropped = np.where(radii < 4.1, 1, 0)
        print("radii")
        print(pd.DataFrame(radii).describe())
        print(pd.DataFrame(indices_cropped).describe())
        np.save(output.indices_cropped, indices_cropped)
# rule run_deeptime_transition_matrix:
#     """
#     A step before MSM - assign every frame of the trajectory to the corresponding cell
#
#     As input we need the trajectory, structure and full array of the grid we wanna assign to.
#
#     As output we get a cell index for every frame of the trajectory.
#     """
#
#     input:
#         trajectory = "experiments/{unique_id}/trajectory.trr",
#         structure = "experiments/{unique_id}/structure.gro",
#     wildcard_constraints:
#         grid_identifier = "deeptime.*"
#     log:
#         log = "experiments/{unique_id}/{grid_identifier}/logging_assignments.log"
#     output:
#         assignments="experiments/{unique_id}/{grid_identifier}/assignments.npy",
#     run:
#         t1 = time()
#         import MDAnalysis as mda
#         from deeptime.clustering import KMeans
#
#         estimator = KMeans(
#             n_clusters=40,# place 100 cluster centers
#             init_strategy='uniform',# uniform initialization strategy
#             max_iter=5000,# don't actually perform the optimization, just place centers
#             fixed_seed=13,
#             n_jobs=8,
#         )
#
#         trajectory_universe = mda.Universe(input.structure,input.trajectory)
#         all_positions = []
#         for ts in trajectory_universe.trajectory:
#             all_positions.extend(ts.positions[3:].flatten())
#         clustering = estimator.fit(np.array(all_positions)).fetch_model()
#         my_assignments = clustering.transform(np.array(all_positions))
#         np.save(output.assignments,my_assignments)
#         t2 = time()
#         log_the_run(wildcards.unique_id, input, output, log.log, None, t2-t1)

rule combine_trajectory:
    input:
        part_traj= expand(f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory_slice_{{i}}.xtc", i=I_TO_ASSIGN, allow_missing=True),
    output:
        assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory_combined.xtc",
    shell:
        """
        #!/bin/bash
        export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
        echo gmx22 trjcat -f {input.part_traj} -o {output.assignments} -cat
        gmx22 trjcat -f {input.part_traj} -o {output.assignments} -cat
        """

rule run_msm_matrix:
    """
    As input we need: assignments.

    As output we want to have the transition matrices for different taus.
    """
    input:
        assignments = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
        indices_cropped=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/indices_cropped.npy",
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/matrix_benchmark.txt"
    output:
        transition_matrix = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/transition_matrix.npz"
    run:
        from scipy.sparse import coo_array, csr_array, diags, dok_array

        from itertools import groupby

        vec = np.load(input.indices_cropped)

        # find sequences and lengths
        # seqs = [(key, length), ...]
        seqs = [(key, len(list(val))) for key, val in groupby(vec)]
        # find start positions of sequences
        # seqs = [(key, start, length), ...]
        seqs = [(key, sum(s[1] for s in seqs[:i]), len) for i, (key, len) in enumerate(seqs)]
        starts_stops = [[s[1], s[1] + s[2] - 1] for s in seqs if s[0] == 1]

        def window(seq: Sequence, len_window: int, step: int = 1) -> Tuple[Any, Any]:
            """
            How this works: returns a list of sublists. Each sublist has two elements: [start_element, end_element].
            Both elements are taken from the seq and are len_window elements apart. The parameter step controls what
            the step between subsequent start_elements is.

            Yields:
                [start_element, end_element] where both elements com from seq where they are len_window positions
                apart

            Example:
                >>> gen_window = window([1, 2, 3, 4, 5, 6], len_window=2, step=3)
                >>> next(gen_window)
                (1, 3)
                >>> next(gen_window)
                (4, 6)
            """
            # in this case always move the window by step and use all points in simulations to count transitions
            for k in range(0,len(seq) - len_window,step):
                start_stop_list = seq[k: k + len_window + 1:len_window]
                if not np.isnan(start_stop_list).any():
                    yield tuple([int(el) for el in start_stop_list if not np.isnan(el)])


        def noncorr_window(seq: Sequence, len_window: int) -> Tuple[Any, Any]:
            """
            Subsample the seq so that only each len_window-th element remains and then similarly return pairs of
            elements.

            Example:
                >>> gen_obj = noncorr_window([1, 2, 3, 4, 5, 6, 7], 3)
                >>> next(gen_obj)
                (1, 4)
                >>> next(gen_obj)
                (4, 7)

            """
            # in this case, only use every len_window-th element for MSM. Faster but loses a lot of data
            return window(seq,len_window,step=len_window)


        class MSM:

            """
            From assignments create a MSM transition matrix
            """

            def __init__(self, assigned_trajectories, total_num_cells: int):
                self.assigned_trajectories = assigned_trajectories
                self.total_num_cells = total_num_cells

            def get_one_tau_transition_matrix(self, tau: float, noncorrelated_windows: bool):
                sparse_count_matrix = dok_array((self.total_num_cells, self.total_num_cells))
                # save the number of transitions between cell with index i and cell with index j
                # count_per_cell = {(i, j): 0 for i in range(self.num_cells) for j in range(self.num_cells)}
                for assigned_trajectory in self.assigned_trajectories:
                    if noncorrelated_windows:
                        window_cell = noncorr_window(assigned_trajectory,int(tau))
                    else:
                        window_cell = window(assigned_trajectory,int(tau))

                    for cell_slice in window_cell:
                        try:
                            if len(cell_slice) < 2:
                                print(cell_slice)
                                pass
                            else:
                                el1, el2 = cell_slice
                                sparse_count_matrix[el1, el2] += 1
                                # enforce detailed balance
                                sparse_count_matrix[el2, el1] += 1
                        except IndexError:
                            raise IndexError(f"Assignments outside of FullGrid borders: {cell_slice} > "
                                             f"{self.total_num_cells, self.total_num_cells}")
                sparse_count_matrix = sparse_count_matrix.tocsr()
                sums = sparse_count_matrix.sum(axis=1)
                # to avoid dividing by zero
                sums[sums == 0] = 1
                # now dividing with counts (actually multiplying with inverse)
                diagonal_values = np.reciprocal(sums)
                diagonal_matrix = diags(diagonal_values,format='csr')
                # Left multiply the CSR matrix with the diagonal matrix
                return diagonal_matrix.dot(sparse_count_matrix)

            def get_all_tau_transition_matrices(self, taus, noncorrelated_windows: bool):
                transition_matrix = np.zeros(shape=taus.shape,dtype=object)
                for tau_i, tau in enumerate(taus):
                    transition_matrix[
                        tau_i] = self.get_one_tau_transition_matrix(tau,noncorrelated_windows=noncorrelated_windows)
                return transition_matrix


        from scipy import sparse

        # load data
        all_assignments = np.load(input.assignments)
        split_assignments = []
        for start, stop in starts_stops:
            split_assignments.append(all_assignments[start:stop])
        num_cells = int(np.nanmax(all_assignments))+1

        my_msm = MSM(split_assignments, total_num_cells=num_cells)
        my_transition_matrices = my_msm.get_one_tau_transition_matrix(
            noncorrelated_windows=False, tau=wildcards.tau)
        # save the result
        sparse.save_npz(output.transition_matrix, my_transition_matrices)
        #t2 = time()
        #log_the_run(wildcards.unique_id, input, output, log.log, None, t2-t1)

rule run_decomposition_msm:
    """
    As output we want to have eigenvalues, eigenvectors. Es input we get a (sparse) rate matrix.
    """
    input:
        transition_matrix = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/transition_matrix.npz"
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/decomposition_benchmark_{{sigma}}_{{which}}.txt"
    output:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_msm_{{sigma}}_{{which}}.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_msm_{{sigma}}_{{which}}.npy"
    params:
        # 1 and LR not right
        tol = 1e-5,
        maxiter = 100000
    run:
        from molgri.molecules.transitions import DecompositionTool
        from scipy import sparse

        # loading
        my_matrix = sparse.load_npz(input.transition_matrix)

        # calculation
        dt = DecompositionTool(my_matrix)
        if wildcards.sigma == "None":
            sigma = None
        else:
            sigma = float(wildcards.sigma)
        print()

        all_eigenval, all_eigenvec = dt.get_decomposition(tol=params.tol, maxiter=params.maxiter,
            which=wildcards.which,
            sigma=sigma)

        # saving to file
        np.save(output.eigenvalues, np.array(all_eigenval))
        np.save(output.eigenvectors, np.array(all_eigenvec))

rule correct_msm_eigenvectors:
    """
    Select only the ones that are not exchanges with boundary
    """
    input:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_msm_{{sigma}}_{{which}}.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_msm_{{sigma}}_{{which}}.npy"
    output:
        corr_eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_correctedmsm_{{sigma}}_{{which}}.npy",
        corr_eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_correctedmsm_{{sigma}}_{{which}}.npy"
    run:
        import numpy as np
        original_eigenvalues = np.load(input.eigenvalues)
        original_eigenvectors = np.load(input.eigenvectors)

        corrected_eigenvalues = []
        corrected_eigenvectors = []
        for one_orig_eigenvalue, one_orig_eigenvec in zip(original_eigenvalues, original_eigenvectors.T):
            eigenvec_len = len(one_orig_eigenvec)
            magnitude_eigenvec = np.abs(one_orig_eigenvec)
            # correct eigenvectors are the ones where over 70% of the total absolute value is in the middle 30%
            success = np.sum(magnitude_eigenvec[int(eigenvec_len/3):int(2*eigenvec_len/3)]) > 0.8*np.sum(magnitude_eigenvec)
            print(np.sum(magnitude_eigenvec[int(eigenvec_len/3):int(2*eigenvec_len/3)]), 0.8*np.sum(magnitude_eigenvec))
            if success:
                corrected_eigenvalues.append(one_orig_eigenvalue)
                corrected_eigenvectors.append(one_orig_eigenvec)
        np.save(output.corr_eigenvalues, np.array(corrected_eigenvalues))
        np.save(output.corr_eigenvectors,np.array(corrected_eigenvectors).T)


rule run_plot_everything_msm:
    """
    Some stuff to plot after a MSM calculation: eigenvalues, ITS, eigenvectors
    """
    input:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}.npy",
    output:
        plot_eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}.png",
        plot_eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.png",
    run:
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=input.eigenvectors,
            tau_array=None)
        # eigenvectors
        pt.plot_eigenvectors_flat(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvectors, height=1200)
        # eigenvalues
        pt.plot_eigenvalues(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvalues)

rule run_plot_its_msm:
    input:
        eigenvalues = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.npy",
            tau=TAUS, allow_missing=True),
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    output:
        plot_its = report(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its_{{is_corrected}}_{{sigma}}_{{which}}.png",
        category="MSM")
    run:
        writeout = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        timesteps = float(read_from_mdrun(input.runfile,"dt"))
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=None,
            tau_array=TAUS)
        print("")
        pt.plot_its_msm(writeout=writeout, time_step_ps=timesteps)
        pt.save_to(output.plot_its)


rule compile_vmd_log:
    """
    Input are the saved eigenvectors. Output = a vmd log that can be used later with:

    vmd <gro file> <xtc file>
    play <vmdlog file>
    """
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.gro",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
        eigenvectors=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}.npy",
        assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
        # in the script only the numbers for frames need to be changed.
        script="molgri/scripts/vmd_show_eigenvectors_ar",
        indices_cropped=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/indices_cropped.npy"
    output:
        vmdlog=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}_vmdlog_msm",
        fig_tga = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}_{{sigma}}_{{which}}_{{is_corrected}}.tga", i=[0, 1, 2, 3, 4], allow_missing=True),
        fig_png= report(expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}_{{sigma}}_{{which}}_{{is_corrected}}.png",i=[0, 1, 2, 3, 4], allow_missing=True),
        category="{unique_id}")
    params:
        num_extremes=30,
        num_eigenvec=5  # only show the first num_eigenvec
    run:
        from molgri.plotting.create_vmdlog import show_eigenvectors_MSM

        eigenvectors = np.load(input.eigenvectors)
        indices_cropped = np.load(input.indices_cropped)
        print("  ")
        print("LEN ASSIGNMENTS", len(np.load(input.assignments)))

        show_eigenvectors_MSM(input.script, output.vmdlog, input.assignments, eigenvector_array=eigenvectors,num_eigenvec=params.num_eigenvec,
            num_extremes=params.num_extremes, figure_paths=output.fig_tga, only_indices=indices_cropped)
        shell("vmd {input.structure} {input.trajectory} < {output.vmdlog}")
        for el_tga, el_png in zip(output.fig_tga, output.fig_png):
            shell("convert {el_tga} {el_png}")


rule print_its:
    input:
        eigenvalues = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.npy",
            sigma="None", which="LR", is_corrected=["msm", "correctedmsm"],allow_missing=True),
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    output:
        data = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/its.csv"
    run:
        import pandas as pd

        writeout = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        timesteps = float(read_from_mdrun(input.runfile,"dt"))

        all_its = []
        for one_eigenvalues_file in input.eigenvalues:
            eigenvals = np.load(one_eigenvalues_file)[1:]  # dropping the first one as it should be zero and cause issues
            all_its.append(-1* np.array(int(wildcards.tau) * writeout * timesteps / np.log(np.abs(eigenvals))))
        my_df = pd.DataFrame(all_its, columns=[f"ITS {i} [ps]" for i in range(1, len(all_its[0])+1)])
        my_df.to_csv(output.data)