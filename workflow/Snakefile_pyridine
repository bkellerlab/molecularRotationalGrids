# add molgri directory
import sys
import numpy as np
sys.path.append(".")

include: "Snakefile_grids"

NUM_MAX_TO_SHOW = 1

from molgri.paths import PATH_OUTPUT_AUTOSAVE, PATH_INPUT_BASEGRO, PATH_EXPERIMENTS
from workflow.snakemake_utils import find_config_parameter_value, modify_topology, modify_mdrun, read_from_mdrun
from molgri.constants import TAUS

rule all:
    input:
        expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/indices_lowest_E.csv", unique_id=["pyridine_sqra_02"], grid_identifier=["pyridine_test4"]),
        #f"{PATH_EXPERIMENTS}pyridine_sqra_01/pyridine_test2/energy.xvg",
        #expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvectors.npy", unique_id=["pyridine_sqra_02"], grid_identifier=["pyridine_test6"]),
        #expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvectors_vmdlog", unique_id=["pyridine_sqra_02"], grid_identifier=["pyridine_test6"]),
        #expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors.png", tau=[10], unique_id=["pyridine_msm_03"], grid_identifier=["pyridine_test5"]),
        #expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}.png", tau=[10], i=[0, 1, 2, 3, 4], unique_id=["pyridine_msm_03"], grid_identifier=["pyridine_test5"]),
        #expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its.png", unique_id=["pyridine_msm_03"], grid_identifier=["pyridine_test5"]),
        #expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its.png", unique_id=["pyridine_sqra_02"], grid_identifier=["pyridine_test6"]),


rule create_config_file_pyridine:
    """
    The point here is to get the unique ID of the experiment, read all of its parameters from a database of experiments 
    and write them to a file within this experiment folder.
    """
    input:
        experiments_database = "workflow/experiments_pyridine.csv"
    output:
        config_file = f"{PATH_EXPERIMENTS}{{unique_id}}/experiment_config.txt"
    run:
        # read in all parameters
        import pandas as pd
        experiments = pd.read_csv(input.experiments_database, index_col=0)
        columns = experiments.columns
        with open(output.config_file, "w") as f:
            print(experiments, wildcards.unique_id)
            for i, parameter_value in enumerate(experiments.loc[wildcards.unique_id]):
                f.write(f"{columns[i]}={parameter_value}\n")


rule prepare_pyridine:
    """
    Start with an end structure of a shorter run to have a good starting structure.
    """
    input:
        single_molecule_gro= f"{PATH_INPUT_BASEGRO}pyridine.pdb",
        two_molecule_gro= f"{PATH_INPUT_BASEGRO}two_pyridine.pdb",
        forcefield1 = f"{PATH_INPUT_BASEGRO}pyridine.itp",
        forcefield1_sqra = f"{PATH_INPUT_BASEGRO}pyridine_sqra.itp",
        forcefield2 = f"{PATH_INPUT_BASEGRO}pyridine_FF/ffG54a7.itp",
        forcefield3= f"{PATH_INPUT_BASEGRO}pyridine_FF/ffG54a7nb.itp",
        forcefield4= f"{PATH_INPUT_BASEGRO}pyridine_FF/ffG54a7bon.itp",
        forcefield5= f"{PATH_INPUT_BASEGRO}pyridine_FF/ff_dum.itp",
        water_in_arg_top = f"{PATH_INPUT_BASEGRO}pyridine.top",
        water_in_arg_top_sqra = f"{PATH_INPUT_BASEGRO}pyridine_sqra.top",
        base_mdp_file = f"{PATH_INPUT_BASEGRO}mdrun.mdp",
        select_group=f"{PATH_INPUT_BASEGRO}select_group_zero",
        select_centers=f"{PATH_INPUT_BASEGRO}select_3_and_0",
        index_m1=f"{PATH_INPUT_BASEGRO}index_first_mol_pyridine.ndx",
        select_two=f"{PATH_INPUT_BASEGRO}select_2",
        select_energy=f"{PATH_INPUT_BASEGRO}select_energy_five",
        select_all_energies=f"{PATH_INPUT_BASEGRO}select_energy_all",
        config_file= f"{PATH_EXPERIMENTS}{{unique_id}}/experiment_config.txt"
    output:
        molecule1 = f"{PATH_EXPERIMENTS}{{unique_id}}/m1.pdb",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.pdb",
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.pdb",
        select_two= f"{PATH_EXPERIMENTS}{{unique_id}}/select_two",
        forcefield1=f"{PATH_EXPERIMENTS}{{unique_id}}/pyridine.itp",
        forcefield1_sqra =f"{PATH_EXPERIMENTS}{{unique_id}}/pyridine_sqra.itp",
        forcefield2=f"{PATH_EXPERIMENTS}{{unique_id}}/ffG54a7.itp",
        forcefield3=f"{PATH_EXPERIMENTS}{{unique_id}}/ffG54a7nb.itp",
        forcefield4=f"{PATH_EXPERIMENTS}{{unique_id}}/ffG54a7bon.itp",
        forcefield5=f"{PATH_EXPERIMENTS}{{unique_id}}/ff_dum.itp",
        runfile = f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{unique_id}}/topology.top",
        topology_sqra = f"{PATH_EXPERIMENTS}{{unique_id}}/topology_sqra.top",
        select_group = f"{PATH_EXPERIMENTS}{{unique_id}}/select_group",
        select_centers = f"{PATH_EXPERIMENTS}{{unique_id}}/select_centers",
        select_energy=f"{PATH_EXPERIMENTS}{{unique_id}}/select_energy",
        select_all_energies=f"{PATH_EXPERIMENTS}{{unique_id}}/select_all_energies",
        index_m1 = f"{PATH_EXPERIMENTS}{{unique_id}}/index_m1.ndx",
    run:
        # todo: create gro strapped of ar atoms
        import shutil
        # stuff that can be copied without being modified
        shutil.copy(input.select_group, output.select_group)
        shutil.copy(input.select_centers,output.select_centers)
        shutil.copy(input.select_all_energies,output.select_all_energies)
        shutil.copy(input.index_m1, output.index_m1)
        shutil.copy(input.forcefield1,output.forcefield1)
        shutil.copy(input.forcefield1_sqra,output.forcefield1_sqra)
        shutil.copy(input.forcefield2,output.forcefield2)
        shutil.copy(input.forcefield3,output.forcefield3)
        shutil.copy(input.forcefield4,output.forcefield4)
        shutil.copy(input.forcefield5,output.forcefield5)
        shutil.copy(input.single_molecule_gro,output.molecule1)
        shutil.copy(input.single_molecule_gro,output.molecule2)
        shutil.copy(input.two_molecule_gro,output.structure)
        shutil.copy(input.select_two,output.select_two)
        shutil.copy(input.select_energy,output.select_energy)

        # depending on config parameters, topology and runfile will be adapted
        shutil.copy(input.water_in_arg_top, output.topology)
        shutil.copy(input.water_in_arg_top_sqra,output.topology_sqra)
        shutil.copy(input.base_mdp_file, output.runfile)

        # modify runfile with given parameters
        trajectory_len = find_config_parameter_value(input.config_file,"traj_len")
        integrator = find_config_parameter_value(input.config_file,"integrator")
        coupling = find_config_parameter_value(input.config_file,"coupling_constant_ps")
        step = find_config_parameter_value(input.config_file, "step_in_ps")
        dielectric_constant = find_config_parameter_value(input.config_file,"epsilon-r")
        modify_mdrun(output.runfile, "integrator", integrator)
        modify_mdrun(output.runfile,"nsteps",trajectory_len)
        modify_mdrun(output.runfile,"nstxout-compressed","20")
        modify_mdrun(output.runfile,"coulombtype","Cut-off")
        modify_mdrun(output.runfile,"dt",step)
        modify_mdrun(output.runfile,"pcoupl","no")
        modify_mdrun(output.runfile,"epsilon-r",dielectric_constant)
        modify_mdrun(output.runfile,"continuation", "yes")
        modify_mdrun(output.runfile,"energygrps", "G214")

        # two reference groups
        modify_mdrun(output.runfile, "tc-grps", "System")
        modify_mdrun(output.runfile,"ref_t", "300")
        modify_mdrun(output.runfile,"tau_t", f"{coupling}")
        #modify_mdrun(output.runfile,"verlet-buffer-tolerance","1e-03")

        # modify topology with given parameters
        #up1_nm = find_config_parameter_value(input.config_file,"up1_nm")
        #up2_nm = find_config_parameter_value(input.config_file,"up2_nm")
        #force = find_config_parameter_value(input.config_file,"force")
        #modify_topology(output.topology,i="1",j="4",funct=10,low=0.0,up1=up1_nm,up2=up2_nm,force_constant=force)

rule run_pt:
    """
    This rule should produce the .gro and .xtc files of the pseudotrajectory.
    """
    wildcard_constraints:
        unique_id=".*sqra.*"
    input:
        molecule1 = f"{PATH_EXPERIMENTS}{{unique_id}}/m1.pdb",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.pdb",
        grid = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_full_array.npy",
    output:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/structure_sqra.pdb",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/trajectory.trr"
    params:
        cell_size_A = 40  # cubic box will be the output, this is size of the box in one dimension
    run:
        from molgri.molecules.writers import PtWriter
        from molgri.molecules.pts import Pseudotrajectory
        from molgri.molecules.parsers import FileParser

        # load grid and molecules
        my_grid = np.load(input.grid)
        my_molecule1 = FileParser(input.molecule1).as_parsed_molecule()
        my_molecule2 = FileParser(input.molecule2).as_parsed_molecule()

        # create PT
        my_pt = Pseudotrajectory(my_molecule2,my_grid)

        # write out .gro and .xtc files
        my_writer = PtWriter("",my_molecule1)
        my_writer.box = (params.cell_size_A, params.cell_size_A, params.cell_size_A, 90, 90, 90)
        #my_writer.write_frames_in_directory(my_pt,path_structure=output.structure,path_trajectory=output.trajectory)
        my_writer.write_full_pt(my_pt,path_structure=output.structure,path_trajectory=output.trajectory)

rule trr_correct:
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/structure_sqra.pdb",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/trajectory.trr"
    output:
        trajectory_corr = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/trajectory_corr.trr",
        index_array = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/array.npy"
    run:
        import MDAnalysis as mda
        from MDAnalysis.analysis import distances

        trajectory_universe = mda.Universe(input.structure,input.trajectory)
        first_molecule = trajectory_universe.select_atoms("bynum 1:11")
        second_molecule = trajectory_universe.select_atoms("bynum 12:22")
        to_keep = []
        for el in trajectory_universe.trajectory:
            dist_arr = distances.distance_array(first_molecule.positions, second_molecule.positions, box=trajectory_universe.dimensions)
            if np.min(dist_arr) > 0.9:
                to_keep.append(el.frame)

        trajectory_universe.atoms.write(output.trajectory_corr,frames=to_keep)

        np.save(output.index_array, np.array(to_keep))

rule gromacs_rerun:
    """
    This rule gets structure, trajectory, topology and gromacs run file as input, as output we are only interested in
    energies.
    """
    wildcard_constraints:
        unique_id=".*sqra.*"
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/structure_sqra.pdb",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/trajectory_corr.trr",
        runfile = f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{unique_id}}/topology_sqra.top",
        select_energy = f"{PATH_EXPERIMENTS}{{unique_id}}/select_energy",
        select_all_energies= f"{PATH_EXPERIMENTS}{{unique_id}}/select_all_energies",
    shadow: "shallow"
    log:
        log = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/logging_gromacs.log"
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/gromacs_benchmark.txt"
    output:
        energy = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/energy.xvg",
        all_energies = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/all_energies.xvg",
    # use with arguments like path_structure path_trajectory path_topology path_default_files path_output_energy
    shell:
        """
        #!/bin/bash
        export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
        gmx22 grompp -f {input.runfile} -c {input.structure} -p {input.topology} -o result.tpr --maxwarn 1 -zero
        gmx22 mdrun -s result.tpr -rerun {input.trajectory} -g {log.log}
        gmx22 energy -f ener.edr -o {output.energy} < {input.select_energy}
        gmx22 energy -f ener.edr -o {output.all_energies} < {input.select_all_energies}
        """

rule lowest_e_structures:
    input:
        energy = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/all_energies.xvg",
    output:
        list_structures = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/indices_lowest_E.csv"
    params:
        energy_type = "Potential",
        num = 50
    run:
        from molgri.space.utils import k_argmin_in_array
        from molgri.molecules.parsers import XVGParser

        my_parsed = XVGParser(input.energy)
        energies2 = my_parsed.get_parsed_energy().get_energies("Coulomb (SR)")
        energies3 = my_parsed.get_parsed_energy().get_energies("Coulomb-14")
        energies4 = my_parsed.get_parsed_energy().get_energies("LJ-14")
        energies5 = my_parsed.get_parsed_energy().get_energies("LJ (SR)")
        energies6 = my_parsed.get_parsed_energy().get_energies("Potential")
        energies7 = my_parsed.get_parsed_energy().get_energies("Disper. corr.")

        energies = energies2 + energies3 + energies4 + energies5 + energies7

        all_lowest_ind = k_argmin_in_array(energies6, k=params.num)
        all_lowest_E = energies6[all_lowest_ind]
        # now additionally sort these from smallest to largest
        sort_index = np.argsort(all_lowest_E)
        sorted_indices = all_lowest_ind[sort_index]
        print("POTENTIAL ")
        print(", ".join([str(x+1) for x in all_lowest_ind]))
        print(all_lowest_E)
        np.savetxt(output.list_structures, sorted_indices)

        all_lowest_ind = k_argmin_in_array(energies, k=params.num)
        all_lowest_E = energies[all_lowest_ind]
        # now additionally sort these from smallest to largest
        sort_index = np.argsort(all_lowest_E)
        sorted_indices = all_lowest_ind[sort_index]
        print("SUM")
        print(", ".join([str(x+1) for x in all_lowest_ind]))
        print(all_lowest_E)
        np.savetxt(output.list_structures, sorted_indices)


rule run_sqra:
    """
    As input we need: energies, adjacency, volume, borders, distances.
    As output we want to have the rate matrix.
    """
    wildcard_constraints:
        unique_id=".*sqra.*"
    input:
        energy = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/all_energies.xvg",
        distances_array = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_distances_array.npz",
        borders_array = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_borders_array.npz",
        volumes = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_volumes.npy",
        config_file = f"{PATH_EXPERIMENTS}{{unique_id}}/experiment_config.txt",
        index_array= f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/array.npy"
    output:
        rate_matrix=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/rate_matrix.npz",
        index_list= f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/index_list.npy",
    params:
        T=273,# temperature in K
        energy_type="Potential",
        m_pyridine=1.3135e-25,  #kg
        upper_lim = 100,
        lower_lim=0.03
    run:
        from molgri.molecules.parsers import XVGParser
        from molgri.molecules.transitions import SQRA
        from scipy import sparse
        from scipy.constants import k as k_B

        tau = coupling = find_config_parameter_value(input.config_file,"coupling_constant_ps")

        D = k_B * params.T * float(tau) * 1e-12 / params.m_pyridine * 1e8  # units should be A^2/ps
        print(f"Diffusion const D={D}")

        # load input files
        all_volumes = np.load(input.volumes)
        all_surfaces = sparse.load_npz(input.borders_array)
        all_distances = sparse.load_npz(input.distances_array)


        my_parsed = XVGParser(input.energy)
        energies = np.full((len(all_volumes)), fill_value=1e30)
        indices = np.load(input.index_array)

        energies2 = my_parsed.get_parsed_energy().get_energies("Coulomb (SR)")
        energies3 = my_parsed.get_parsed_energy().get_energies("Coulomb-14")
        energies4 = my_parsed.get_parsed_energy().get_energies("LJ-14")
        energies5 = my_parsed.get_parsed_energy().get_energies("LJ (SR)")
        energies7 = my_parsed.get_parsed_energy().get_energies("Disper. corr.")

        energies[indices]=energies2 + energies3 + energies4 + energies5 + energies7
        print(len(np.where(energies > 1e10)[0]), len(energies))
        #energies = my_parsed.get_parsed_energy().get_energies(params.energy_type)



        sqra = SQRA(energies=energies,volumes=all_volumes,distances=all_distances,surfaces=all_surfaces)
        rate_matrix = sqra.get_rate_matrix(D,params.T)
        rate_matrix, index_list = sqra.cut_and_merge(rate_matrix,T=params.T,lower_limit=params.lower_lim,
            upper_limit=params.upper_lim)

        print(np.nanmax(rate_matrix.data),np.nanmin(rate_matrix.data),np.nanmean(rate_matrix.data),np.nanstd(rate_matrix.data), len(indices))

        # saving to file
        sparse.save_npz(output.rate_matrix,rate_matrix)
        np.save(output.index_list,np.array(index_list,dtype=object))

rule run_decomposition:
    """
    As output we want to have eigenvalues, eigenvectors. Es input we get a (sparse) rate matrix.
    """
    wildcard_constraints:
        unique_id=".*sqra.*"
    input:
        rate_matrix = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/rate_matrix.npz",
    output:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvalues.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvectors.npy",
    params:
        tol=1e-5,
        maxiter=100000,
        sigma=0,
        which="SR"
    run:
        from scipy import sparse
        from molgri.molecules.transitions import DecompositionTool

        # loading
        my_matrix = sparse.load_npz(input.rate_matrix)

        if params.sigma == "None":
            sigma = None
        else:
            sigma = float(params.sigma)
        # calculation
        dt = DecompositionTool(my_matrix)
        all_eigenval, all_eigenvec = dt.get_decomposition(tol=params.tol, maxiter=params.maxiter, which=params.which,
            sigma=sigma)

        # saving to file
        np.save(output.eigenvalues,np.array(all_eigenval))
        np.save(output.eigenvectors,np.array(all_eigenvec))

rule run_plot_everything_sqra:
    """
    Make a plot of eigenvalues
    """
    wildcard_constraints:
        unique_id=".*sqra.*"
    input:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvalues.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvectors.npy",
    output:
        plot_eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvalues.png",
        plot_eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvectors.png",
        plot_its=report(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its.png", category="{unique_id}"),
    run:
        from molgri.plotting.transition_plots import PlotlyTransitions

        pt = PlotlyTransitions(is_msm=False,path_eigenvalues=input.eigenvalues,path_eigenvectors=input.eigenvectors)
        # eigenvectors
        pt.plot_eigenvectors_flat()
        pt.save_to(output.plot_eigenvectors,height=1200)
        # eigenvalues
        pt.plot_eigenvalues()
        pt.save_to(output.plot_eigenvalues)
        # # its for msm
        pt.plot_its_as_line()
        pt.save_to(output.plot_its)
        # we could also plot the heatmap of the matrix, but it's honestly not that useful and can become very large

rule compile_vmd_pyridine:
    """
    Input are the saved eigenvectors. Output = a vmd log that can be used later with:

    vmd <gro file> <xtc file>
    play <vmdlog file>
    """
    wildcard_constraints:
        unique_id=".*sqra.*"
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/structure_sqra.pdb",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/trajectory.trr",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvectors.npy",
        index_list= f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/index_list.npy",
        # in the script only the numbers for frames need to be changed.
        script="molgri/scripts/vmd_show_eigenvectors_sqra_pyridine"
    output:
        vmdlog = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvectors_vmdlog",
        fig_tga = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvector_{{i}}.tga", i=[0, 1, 2, 3, 4], allow_missing=True),
        fig_png= report(expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/eigenvector_{{i}}.png",i=[0, 1, 2, 3, 4], allow_missing=True),
        category="{unique_id}")
    params:
        num_extremes=NUM_MAX_TO_SHOW,
        num_eigenvec=6  # only show the first num_eigenvec
    run:
        from molgri.plotting.create_vmdlog import show_eigenvectors

        # load eigenvectors
        eigenvectors = np.load(input.eigenvectors)
        print(input.script)
        index_list = np.load(input.index_list,allow_pickle=True)
        if not np.any(index_list):
            index_list = None
        else:
            index_list = list(index_list)
        show_eigenvectors(input.script,output.vmdlog,eigenvector_array=eigenvectors,num_eigenvec=params.num_eigenvec,
            num_extremes=params.num_extremes,index_list=index_list, figure_paths=output.fig_tga)
        shell("vmd {input.structure} {input.trajectory} < {output.vmdlog}")
        for el_tga, el_png in zip(output.fig_tga, output.fig_png):
            shell("convert {el_tga} {el_png}")

# rule create_msm_gro:
#     """
#     Create a structure from two molecules. Expected in the folder: m1.gro, m2.gro
#     """
#     wildcard_constraints:
#         unique_id=".*msm.*"
#     input:
#         molecule1 = f"{PATH_EXPERIMENTS}{{unique_id}}/m1.pdb",
#         molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.pdb",
#     output:
#         structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.pdb"
#     params:
#         start_dist_A = 6,  # distance between centers of mass of both molecules in the combined structure
#         cell_size_A = 30  # cubic box will be the output, this is size of the box in one dimension
#     run:
#         import MDAnalysis as mda
#         from MDAnalysis import Merge
#         from scipy.spatial.transform import Rotation
#
#         central_molecule = mda.Universe(input.molecule1)
#         moving_molecule = mda.Universe(input.molecule2)
#
#         # center the both molecules
#         com1 = central_molecule.atoms.center_of_mass()
#         com2 = moving_molecule.atoms.center_of_mass()
#         central_molecule.atoms.translate(-com1)
#         moving_molecule.atoms.translate(-com2)
#         # translate the second one
#         moving_molecule.atoms.translate([0, 0, float(params.start_dist_A)])
#         moving_molecule.atoms.rotate(Rotation.random().as_matrix(), point=moving_molecule.atoms.center_of_mass())
#
#         # merge and write
#         merged_u = Merge(central_molecule.atoms, moving_molecule.atoms)
#         merged_u.dimensions = (params.cell_size_A, params.cell_size_A, params.cell_size_A, 90, 90, 90)
#         with mda.Writer(output.structure) as writer:
#             writer.write(merged_u)

rule run_msm_gromacs:
    """
    This rule gets structure, trajectory, topology and gromacs run file as input, as output we are only interested in
    energies.
    """
    wildcard_constraints:
        unique_id=".*msm.*"
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.pdb",
        runfile = f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{unique_id}}/topology.top",
        select_group = f"{PATH_EXPERIMENTS}{{unique_id}}/select_group",
        select_energy = f"{PATH_EXPERIMENTS}{{unique_id}}/select_energy",
        index_m1 = f"{PATH_EXPERIMENTS}{{unique_id}}/index_m1.ndx",
        select_centers= f"{PATH_EXPERIMENTS}{{unique_id}}/select_centers",
    shadow: "shallow"
    log:
         log = "experiments/{unique_id}/logging_gromacs.log"
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/gromacs_benchmark.txt"
    output:
        energy = f"{PATH_EXPERIMENTS}{{unique_id}}/energy.xvg",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
        temp = f"{PATH_EXPERIMENTS}{{unique_id}}/temp.xtc"
    shell:
        """
        #!/bin/bash
        export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
        gmx22 grompp -f {input.runfile} -o result.tpr -c {input.structure} -p {input.topology} --maxwarn 1
        gmx22 trjconv -f {input.structure} -s result.tpr -o temp.trr < {input.select_group}
        gmx22 mdrun -s result.tpr -x {output.temp} -e ener.edr -g {log.log}
        gmx22 energy -f ener.edr -o {output.energy} < {input.select_energy}
        gmx22 trjconv -f {output.temp} -s result.tpr -pbc mol -center -o temp2.trr -n {input.index_m1} < {input.select_centers}
        gmx22 trjconv -fit rot+trans -f temp2.trr -o {output.trajectory} -s {input.structure} -n {input.index_m1} < {input.select_centers}
        """

rule run_trajectory_assignment:
    """
    A step before MSM - assign every frame of the trajectory to the corresponding cell

    As input we need the trajectory, structure and full array of the grid we wanna assign to.

    As output we get a cell index for every frame of the trajectory.
    """
    wildcard_constraints:
        unique_id=".*msm.*"
    input:
        full_array = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_full_array.npy",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.pdb",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.pdb",
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignment_benchmark.txt"
    output:
        assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
    run:
        from molgri.molecules.transitions import AssignmentTool
        from tqdm import tqdm

        # using all inputs
        my_grid = np.load(input.full_array)
        at = AssignmentTool(my_grid,input.structure,input.trajectory,input.molecule2,n_jobs=5,start=None,stop=None)
        np.save(output.assignments,at.get_full_assignments())

rule run_msm_matrix:
    """
    As input we need: assignments.

    As output we want to have the transition matrices for different taus.
    """
    wildcard_constraints:
        unique_id=".*msm.*"
    input:
        assignments = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
    output:
        transition_matrix = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/transition_matrix.npz"
    run:
        #t1 = time()
        from molgri.molecules.transitions import MSM
        from scipy import sparse

        # load data
        my_assignments = np.load(input.assignments)
        num_cells = int(np.nanmax(my_assignments)) + 1

        my_msm = MSM(assigned_trajectory=my_assignments, total_num_cells=num_cells)
        my_transition_matrices = my_msm.get_one_tau_transition_matrix(
            noncorrelated_windows=False, tau=wildcards.tau)
        # save the result
        sparse.save_npz(output.transition_matrix, my_transition_matrices)
        #t2 = time()
        #log_the_run(wildcards.unique_id, input, output, log.log, None, t2-t1)

rule run_decomposition_msm:
    """
    As output we want to have eigenvalues, eigenvectors. Es input we get a (sparse) rate matrix.
    """
    wildcard_constraints:
        unique_id=".*msm.*"
    input:
        transition_matrix = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/transition_matrix.npz"
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/decomposition_benchmark.txt"
    output:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors.npy"
    params:
        # 1 and LR not right
        tol = 1e-5,
        maxiter = 100000,
        sigma=None,
        which="LR"
    run:
        from molgri.molecules.transitions import DecompositionTool
        from scipy import sparse

        # loading
        my_matrix = sparse.load_npz(input.transition_matrix)

        # calculation
        dt = DecompositionTool(my_matrix)
        all_eigenval, all_eigenvec = dt.get_decomposition(tol=params.tol, maxiter=params.maxiter,
            which=params.which,
            sigma=params.sigma)

        # saving to file
        np.save(output.eigenvalues, np.array(all_eigenval))
        np.save(output.eigenvectors, np.array(all_eigenvec))

rule run_plot_everything_msm:
    """
    Some stuff to plot after a MSM calculation: eigenvalues, ITS, eigenvectors
    """
    wildcard_constraints:
        unique_id=".*msm.*"
    input:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors.npy",
    output:
        plot_eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors.png",
        plot_eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues.png",
    run:
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=input.eigenvectors,
            tau_array=TAUS)
        #print("new")
        # eigenvectors
        pt.plot_eigenvectors_flat(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvectors, height=1200)
        # eigenvalues
        pt.plot_eigenvalues(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvalues)

rule run_plot_its_msm:
    wildcard_constraints:
        unique_id=".*msm.*"
    input:
        eigenvalues = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues.npy",
            tau=TAUS, allow_missing=True),
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    output:
        plot_its = report(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its.png",
        category="{unique_id}")
    run:
        writeout = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        timesteps = float(read_from_mdrun(input.runfile,"dt"))
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=None,
            tau_array=TAUS)
        pt.plot_its_msm(writeout=writeout, time_step_ps=timesteps)
        #pt.fig.update_layout(title=r"Temp. coupling 10 ps",title_x=0.5)
        pt.save_to(output.plot_its)


rule compile_vmd_log:
    """
    Input are the saved eigenvectors. Output = a vmd log that can be used later with:

    vmd <gro file> <xtc file>
    play <vmdlog file>
    """
    wildcard_constraints:
        unique_id=".*msm.*"
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.pdb",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
        eigenvectors=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors.npy",
        assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
        # in the script only the numbers for frames need to be changed.
        script="molgri/scripts/vmd_show_eigenvectors_msm_pyridine"
    output:
        vmdlog=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_vmdlog",
        fig_tga = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}.tga", i=[0, 1, 2, 3, 4], allow_missing=True),
        fig_png= report(expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}.png",i=[0, 1, 2, 3, 4], allow_missing=True),
        category="{unique_id}")
    params:
        num_extremes=NUM_MAX_TO_SHOW,
        num_eigenvec=5  # only show the first num_eigenvec
    run:
        from molgri.plotting.create_vmdlog import show_eigenvectors_MSM

        eigenvectors = np.load(input.eigenvectors)

        show_eigenvectors_MSM(input.script, output.vmdlog, input.assignments, eigenvector_array=eigenvectors,num_eigenvec=params.num_eigenvec,
            num_extremes=params.num_extremes, figure_paths=output.fig_tga)
        shell("vmd {input.structure} {input.trajectory} < {output.vmdlog}")
        for el_tga, el_png in zip(output.fig_tga, output.fig_png):
            shell("convert {el_tga} {el_png}")