"""
All of the workflows relating to production of trajectories, subsequent MSMs and their related outputs (figures ...)
"""
# add molgri directory
import sys
sys.path.append(".")
import numpy as np
import yaml


from molgri.paths import PATH_OUTPUT_AUTOSAVE, PATH_INPUT_BASEGRO, PATH_EXPERIMENTS
from workflow.snakemake_utils import modify_mdrun, modify_topology, read_from_mdrun

include: "run_grid"

PATH_EXPERIMENTS = "ex_exp/"


# here add other experiment types that should be performed with this pipeline
if config["experiment_type"] not in ["msm_water_in_vacuum"]:
    raise AttributeError(f"This pipeline should be used for MSM experiments. Your experiment type {config['experiment_type']} is not available here.")

EXPERIMENT_TYPE = config["experiment_type"]
EXPERIMENT_ID = config["experiment_id"]
GRID_ID = config["grid_identifier"]
TAUS = np.array(config["params_msm"]["taus_msm_all"])
TAUS_TO_PLOT = np.array(config["params_msm"]["taus_msm_to_plot"])


rule all:
    input:
        expand(f"{PATH_EXPERIMENTS}{EXPERIMENT_TYPE}/{EXPERIMENT_ID}/{GRID_ID}/{{what}}", what=["its.png"]),
        expand(f"{PATH_EXPERIMENTS}{EXPERIMENT_TYPE}/{EXPERIMENT_ID}/{GRID_ID}/{{tau}}/{{what}}", tau=TAUS_TO_PLOT,
            what=["eigenvectors_vmdlog", "eigenvalues.png", "its.csv"])
    log:
        logfile = f"{PATH_EXPERIMENTS}{EXPERIMENT_TYPE}/{EXPERIMENT_ID}/{GRID_ID}/record_config.yaml",
    run:
        with open(log.logfile,"w") as f:
            yaml.dump(config,f)

rule prepare_water_in_vacuum:
    """
    Here, everything is specific to a water-water system set up. Create a new folder in experiments/ and populate it
    with correctly defined inputs for the gromacs run etc.
    """
    wildcard_constraints:
        experiment_type=".*water_in_vacuum.*"
    input:
        water_gro = f"{PATH_INPUT_BASEGRO}H2O.gro",
        water_top = f"{PATH_INPUT_BASEGRO}H2O_H2O.top",
        base_mdp_file = f"{PATH_INPUT_BASEGRO}mdrun.mdp",
        select_group=f"{PATH_INPUT_BASEGRO}select_group_zero",
        select_centers=f"{PATH_INPUT_BASEGRO}select_3_and_0",
        index_m1=f"{PATH_INPUT_BASEGRO}index_first_mol.ndx",
    output:
        molecule1 = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/m1.gro",
        molecule2 = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/m2.gro",
        runfile = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/topology.top",
        select_group = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/select_group",
        select_centers = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/select_centers",
        index_m1 = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/index_m1.ndx",
    params:
        nsteps = config["params_setup"]["nsteps"],
        integrator = config["params_setup"]["integrator"],
        dt_ps = config["params_setup"]["dt_ps"],
        energy_writeout_frequency = config["params_setup"]["energy_writeout_frequency"],
        compressed_writeout_frequency = config["params_setup"]["compressed_writeout_frequency"],
        epsilon = config["params_setup"]["epsilon"],
        tau_t= config["params_setup"]["tau_t"],
        up1_nm= config["params_setup"]["up1_nm"],
        up2_nm= config["params_setup"]["up2_nm"],
        force_constant_restraint= config["params_setup"]["force_constant_restraint"],
    run:
        import shutil
        # stuff that can be copied without being modified
        shutil.copy(input.water_gro,output.molecule1)
        shutil.copy(input.water_gro,output.molecule2)
        shutil.copy(input.select_group, output.select_group)

        shutil.copy(input.select_centers,output.select_centers)
        shutil.copy(input.index_m1, output.index_m1)

        # depending on config parameters, topology and runfile will be adapted
        shutil.copy(input.water_top, output.topology)
        shutil.copy(input.base_mdp_file, output.runfile)

        # modify runfile with given parameters
        modify_mdrun(output.runfile, "integrator", params.integrator)
        modify_mdrun(output.runfile,"nsteps",params.nsteps)
        modify_mdrun(output.runfile,"tau_t",params.tau_t)
        modify_mdrun(output.runfile,"dt",params.dt_ps)
        modify_mdrun(output.runfile,"nstenergy", params.energy_writeout_frequency)
        modify_mdrun(output.runfile,"nstxout-compressed",params.compressed_writeout_frequency)
        modify_mdrun(output.runfile,"epsilon-r",params.epsilon)
        # modify topology with given parameters
        modify_topology(output.topology,i="1",j="4",funct=10,low=0.0,up1=params.up1_nm,up2=params.up2_nm,
            force_constant=params.force_constant_restraint)


# note: here we don't wanna refer to specific rule outputs as different rules for set up may be used
rule create_msm_gro:
    """
    Create a structure from two molecules. Expected in the folder: m1.gro, m2.gro
    """
    input:
        molecule1 = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/m1.gro",
        molecule2 = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/m2.gro",
    output:
        structure = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/structure.gro"
    params:
        start_dist_A = config["params_msm"]["start_dist_A"],  # distance between centers of mass of both molecules in the combined structure
        cell_size_A = config["params_msm"]["cell_size_A"]  # cubic box will be the output, this is size of the box in one dimension
    run:
        import MDAnalysis as mda
        from MDAnalysis import Merge
        from scipy.spatial.transform import Rotation

        central_molecule = mda.Universe(input.molecule1)
        moving_molecule = mda.Universe(input.molecule2)

        # center the both molecules
        com1 = central_molecule.atoms.center_of_mass()
        com2 = moving_molecule.atoms.center_of_mass()
        central_molecule.atoms.translate(-com1)
        moving_molecule.atoms.translate(-com2)
        # translate the second one
        moving_molecule.atoms.translate([0, 0, float(params.start_dist_A)])
        moving_molecule.atoms.rotate(Rotation.random().as_matrix(), point=moving_molecule.atoms.center_of_mass())

        # merge and write
        merged_u = Merge(central_molecule.atoms, moving_molecule.atoms)
        merged_u.dimensions = (params.cell_size_A, params.cell_size_A, params.cell_size_A, 90, 90, 90)
        with mda.Writer(output.structure) as writer:
            writer.write(merged_u)

rule run_msm_gromacs:
    """
    This rule gets structure, trajectory, topology and gromacs run file as input, as output we are only interested in
    energies.
    """
    input:
        structure = rules.create_msm_gro.output.structure,
        runfile = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/topology.top",
        select_group = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/select_group",
        index_m1 = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/index_m1.ndx",
        select_centers= f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/select_centers",
    shadow: "shallow"
    log:
         log = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/logging_gromacs.log"
    benchmark:
        f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/gromacs_benchmark.txt"
    output:
        trajectory = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/trajectory.xtc",
        temp = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/temp.xtc"
    shell:
        """
        #!/bin/bash
        export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
        gmx22 grompp -f {input.runfile} -o result.tpr -c {input.structure} -p {input.topology}
        gmx22 trjconv -f {input.structure} -s result.tpr -o temp.trr < {input.select_group}
        gmx22 mdrun -s result.tpr -x {output.temp} -e ener.edr -g {log.log}
        gmx22 trjconv -f {output.temp} -s result.tpr -pbc mol -center -o temp2.trr -n {input.index_m1} < {input.select_centers}
        gmx22 trjconv -fit rot+trans -f temp2.trr -o {output.trajectory} -s {input.structure} -n {input.index_m1} < {input.select_centers}
        """



rule run_trajectory_assignment:
    """
    A step before MSM - assign every frame of the trajectory to the corresponding cell

    As input we need the trajectory, structure and full array of the grid we wanna assign to.

    As output we get a cell index for every frame of the trajectory.
    """

    input:
        full_array = rules.run_grid.output.full_array,
        trajectory = rules.run_msm_gromacs.output.trajectory,
        structure = rules.create_msm_gro.output.structure,
        molecule2 = rules.create_msm_gro.input.molecule2,
        runfile= rules.run_msm_gromacs.input.runfile,
    benchmark:
        f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/assignment_benchmark.txt"
    output:
        assignments=f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/assignments.npy",
    params:
        include_outliers = config["params_msm"]["include_outliers"]
    run:
        from molgri.molecules.transitions import AssignmentTool

        # using all inputs
        my_grid = np.load(input.full_array)

        at = AssignmentTool(my_grid,input.structure,input.trajectory, input.molecule2)
        assignments = at.get_full_assignments()
        print("NUM NANS1", np.count_nonzero(np.isnan(assignments)))

        # saving output
        np.save(output.assignments,assignments)

# rule combine_trajectory_assignment:
#     """
#     A step before MSM - assign every frame of the trajectory to the corresponding cell
#
#     As input we need the trajectory, structure and full array of the grid we wanna assign to.
#
#     As output we get a cell index for every frame of the trajectory.
#     """
#     input:
#         part_assignments = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments_{{i}}.npy",i=ALL_I,  allow_missing=True)
#     output:
#         assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
#     benchmark:
#         f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/combine_assignment_benchmark.txt"
#     run:
#         print(input.part_assignments)
#         all_assignments = []
#         for one_assignment_file in input.part_assignments:
#             one_file = np.load(one_assignment_file)
#             print(one_assignment_file, one_file.shape)
#             all_assignments.append(one_file)
#         # saving output
#         all_assignments = np.concatenate(all_assignments)
#         print("SHAPE", all_assignments.shape)
#         np.save(output.assignments, all_assignments)
#
# rule combine_trajectory:
#     input:
#         part_traj= expand(f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory_slice2_{{i}}.xtc", i=ALL_I, allow_missing=True)
#     output:
#         assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory_combined.xtc",
#     shell:
#         """
#         #!/bin/bash
#         export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
#         echo gmx22 trjcat -f {input.part_traj} -o {output.assignments} -cat
#         gmx22 trjcat -f {input.part_traj} -o {output.assignments} -cat
#         """

# rule run_deeptime_transition_matrix:
#     """
#     A step before MSM - assign every frame of the trajectory to the corresponding cell
#
#     As input we need the trajectory, structure and full array of the grid we wanna assign to.
#
#     As output we get a cell index for every frame of the trajectory.
#     """
#
#     input:
#         trajectory = "experiments/{unique_id}/trajectory.trr",
#         structure = "experiments/{unique_id}/structure.gro",
#     wildcard_constraints:
#         grid_identifier = "deeptime.*"
#     log:
#         log = "experiments/{unique_id}/{grid_identifier}/logging_assignments.log"
#     output:
#         assignments="experiments/{unique_id}/{grid_identifier}/assignments.npy",
#     run:
#         t1 = time()
#         import MDAnalysis as mda
#         from deeptime.clustering import KMeans
#
#         estimator = KMeans(
#             n_clusters=40,# place 100 cluster centers
#             init_strategy='uniform',# uniform initialization strategy
#             max_iter=5000,# don't actually perform the optimization, just place centers
#             fixed_seed=13,
#             n_jobs=8,
#         )
#
#         trajectory_universe = mda.Universe(input.structure,input.trajectory)
#         all_positions = []
#         for ts in trajectory_universe.trajectory:
#             all_positions.extend(ts.positions[3:].flatten())
#         clustering = estimator.fit(np.array(all_positions)).fetch_model()
#         my_assignments = clustering.transform(np.array(all_positions))
#         np.save(output.assignments,my_assignments)
#         t2 = time()
#         log_the_run(wildcards.unique_id, input, output, log.log, None, t2-t1)

rule run_msm_matrix:
    """
    As input we need: assignments.

    As output we want to have the transition matrices for different taus.
    """
    input:
        assignments = rules.run_trajectory_assignment.output.assignments,
    benchmark:
        f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/matrix_benchmark.txt"
    output:
        transition_matrix = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/transition_matrix.npz"
    run:
        from molgri.molecules.transitions import MSM
        from scipy import sparse

        # load data
        my_assignments = np.load(input.assignments)
        print("LOADED NUM NANS3",np.count_nonzero(np.isnan(my_assignments)))
        num_cells = int(np.nanmax(my_assignments))+1

        my_msm = MSM(assigned_trajectory=my_assignments, total_num_cells=num_cells)
        my_transition_matrices = my_msm.get_one_tau_transition_matrix(
            noncorrelated_windows=False, tau=wildcards.tau)
        # save the result
        sparse.save_npz(output.transition_matrix, my_transition_matrices)

rule run_decomposition_msm:
    """
    As output we want to have eigenvalues, eigenvectors. Es input we get a (sparse) rate matrix.
    """
    input:
        transition_matrix = rules.run_msm_matrix.output.transition_matrix
    benchmark:
        f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/decomposition_benchmark.txt"
    output:
        eigenvalues = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors.npy"
    params:
        # 1 and LR not right
        tol = config["params_msm"]["tol"],
        maxiter = config["params_msm"]["maxiter"],
        sigma = config["params_msm"]["sigma"],
        which = config["params_msm"]["which"]
    run:
        from molgri.molecules.transitions import DecompositionTool
        from scipy import sparse

        # loading
        my_matrix = sparse.load_npz(input.transition_matrix)

        # calculation
        dt = DecompositionTool(my_matrix)
        if params.sigma == "None":
            sigma = None
        else:
            sigma = float(params.sigma)

        all_eigenval, all_eigenvec = dt.get_decomposition(tol=params.tol, maxiter=params.maxiter,
            which=params.which,
            sigma=sigma)

        # saving to file
        np.save(output.eigenvalues, np.array(all_eigenval))
        np.save(output.eigenvectors, np.array(all_eigenvec))

rule run_plot_everything_msm:
    """
    Some stuff to plot after a MSM calculation: eigenvalues, ITS, eigenvectors
    """
    input:
        eigenvalues = rules.run_decomposition_msm.output.eigenvalues,
        eigenvectors = rules.run_decomposition_msm.output.eigenvectors
    output:
        plot_eigenvectors = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors.png",
        plot_eigenvalues = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues.png",
    run:
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=input.eigenvectors,
            tau_array=None)
        # eigenvectors
        pt.plot_eigenvectors_flat(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvectors, height=1200)
        # eigenvalues
        pt.plot_eigenvalues(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvalues)

rule run_plot_its_msm:
    input:
        eigenvalues = expand(f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues.npy",
            tau=TAUS, allow_missing=True),
        runfile= rules.run_msm_gromacs.input.runfile
    output:
        plot_its = report(f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/its.png",
        category="MSM")
    run:
        writeout = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        timesteps = float(read_from_mdrun(input.runfile,"dt"))
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=None,
            tau_array=TAUS)
        pt.plot_its_msm(writeout=writeout, time_step_ps=timesteps)
        pt.save_to(output.plot_its)


rule compile_vmd_log:
    """
    Input are the saved eigenvectors. Output = a vmd log that can be used later with:

    vmd <gro file> <xtc file>
    play <vmdlog file>
    """
    input:
        structure = rules.create_msm_gro.output.structure,
        trajectory = rules.run_msm_gromacs.output.trajectory,
        eigenvectors=rules.run_decomposition_msm.output.eigenvectors,
        assignments=rules.run_trajectory_assignment.output.assignments,
        # in the script only the numbers for frames need to be changed.
        script="molgri/scripts/vmd_show_eigenvectors_ar"
    output:
        vmdlog=f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_vmdlog",
        fig_tga = expand(f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector{{i}}.tga", i=[0, 1, 2, 3, 4], allow_missing=True),
        fig_png= report(expand(f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector{{i}}.png",i=[0, 1, 2, 3, 4], allow_missing=True),
        category="{unique_id}")
    params:
        num_extremes=config["params_msm"]["num_extremes_to_plot"],
        num_eigenvec=config["params_msm"]["num_eigenvec_to_plot"]
    run:
        from molgri.plotting.create_vmdlog import show_eigenvectors_MSM
        eigenvectors = np.load(input.eigenvectors)

        show_eigenvectors_MSM(input.script, output.vmdlog, input.assignments, eigenvector_array=eigenvectors,num_eigenvec=params.num_eigenvec,
            num_extremes=params.num_extremes, figure_paths=output.fig_tga)
        print("created otput.vmd")
        shell("vmd -dispdev text {input.structure} {input.trajectory} < {output.vmdlog}")
        print("created tga")
        for el_tga, el_png in zip(output.fig_tga, output.fig_png):
            shell("convert {el_tga} {el_png}")


rule print_its:
    input:
        eigenvalues = rules.run_decomposition_msm.output.eigenvalues,
        runfile= rules.run_msm_gromacs.input.runfile
    output:
        data = f"{PATH_EXPERIMENTS}{{experiment_type}}/{{unique_id}}/{{grid_identifier}}/{{tau}}/its.csv"
    run:
        import pandas as pd

        try:
            writeout = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        except TypeError:
            writeout = int(read_from_mdrun(input.runfile,"nstxout"))
        timesteps = float(read_from_mdrun(input.runfile,"dt"))

        all_its = []
        eigenvals = np.load(input.eigenvalues)[1:]  # dropping the first one as it should be zero and cause issues
        all_its.append(-1*  np.array(int(wildcards.tau) * writeout * timesteps / np.log(np.abs(eigenvals))))
        my_df = pd.DataFrame(all_its, columns=[f"ITS {i} [ps]" for i in range(1, len(all_its[0])+1)])
        my_df.to_csv(output.data)
