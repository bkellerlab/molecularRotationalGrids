"""
All of the workflows relating to production of trajectories, subsequent MSMs and their related outputs (figures ...)
"""
# add molgri directory
import sys
sys.path.append(".")
from functools import partial
from multiprocessing import Pool
from time import time
import MDAnalysis as mda
import numpy as np
import pandas as pd



from MDAnalysis.analysis.base import AnalysisFromFunction
from numpy.typing import NDArray
from scipy.spatial.distance import cdist

from molgri.space.fullgrid import from_full_array_to_o_b_t
from molgri.space.utils import normalise_vectors



from molgri.paths import PATH_OUTPUT_AUTOSAVE, PATH_INPUT_BASEGRO, PATH_EXPERIMENTS
from workflow.snakemake_utils import find_config_parameter_value, log_the_run, modify_mdrun, modify_topology, \
    read_from_mdrun
from molgri.constants import TAUS


include: "Snakefile_grids"

#wildcard_constraints:
#    unique_id=".*msm.*"

ALL_I = [1, 2]


rule all:
    input:
        #f"MSM4_electrostatic_{elec}_cc_{cc}" for elec in ["1"] for cc in ["1", "01", "001", "0001"]
        expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/its.csv", unique_id=[f"vacuum_msm_0{i}" for i in [1,2,3,4]], grid_identifier=["80_80_very_short"], tau=[10]),
        # expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}_{{sigma}}_{{which}}_{{is_corrected}}.png",i=[0, 1, 2, 3, 4],
        # unique_id=["msm_tau_05", "msm_tau_06", "msm_tau_07"],grid_identifier=["80_80_very_short"],sigma="None",which="LR",
        # tau=[10],suffix=["_vmdlog_msm"],is_corrected=["msm"])
        msm_all1 = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its_{{is_corrected}}_{{sigma}}_{{which}}.png",
            unique_id=[f"vacuum_msm_0{i}" for i in [1,2,3,4]], tau=10,
            grid_identifier=["80_80_very_short"], sigma=None, which="LR", is_corrected = ["msm"]),
        msm_all3=expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}{{suffix}}",
            unique_id=[f"vacuum_msm_0{i}" for i in [1,2,3,4]],
            grid_identifier=["80_80_very_short"],sigma="None",which="LR",
            tau=[10],suffix=["_vmdlog_msm"],is_corrected=["msm"])

rule create_config_file:
    """
    The point here is to get the unique ID of the experiment, read all of its parameters from a database of experiments
    and write them to a file within this experiment folder.
    """
    input:
        experiments_database = "workflow/experiments.csv"
    output:
        config_file = f"{PATH_EXPERIMENTS}{{unique_id}}/experiment_config.txt"
    run:
        # read in all parameters
        import pandas as pd
        experiments = pd.read_csv(input.experiments_database, index_col=0)
        columns = experiments.columns
        with open(output.config_file, "w") as f:
            print(experiments, wildcards.unique_id)
            for i, parameter_value in enumerate(experiments.loc[wildcards.unique_id]):
                f.write(f"{columns[i]}={parameter_value}\n")

rule prepare_water_water:
    """
    Here, everything is specific to a water-water system set up. Create a new folder in experiments/ and populate it
    with correctly defined inputs for the gromacs run etc.
    """
    input:
        water_gro = f"{PATH_INPUT_BASEGRO}H2O.gro",
        water_top = f"{PATH_INPUT_BASEGRO}H2O_H2O.top",
        base_mdp_file = f"{PATH_INPUT_BASEGRO}mdrun.mdp",
        select_group=f"{PATH_INPUT_BASEGRO}select_group_zero",
        select_energy=f"{PATH_INPUT_BASEGRO}select_energy_five",
        select_centers=f"{PATH_INPUT_BASEGRO}select_3_and_0",
        index_m1=f"{PATH_INPUT_BASEGRO}index_first_mol.ndx",
        config_file = f"{PATH_EXPERIMENTS}{{unique_id}}/experiment_config.txt"
    output:
        molecule1 = f"{PATH_EXPERIMENTS}{{unique_id}}/m1.gro",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.gro",
        runfile = f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{unique_id}}/topology.top",
        select_group = f"{PATH_EXPERIMENTS}{{unique_id}}/select_group",
        select_energy = f"{PATH_EXPERIMENTS}{{unique_id}}/select_energy",
        select_centers = f"{PATH_EXPERIMENTS}{{unique_id}}/select_centers",
        index_m1 = f"{PATH_EXPERIMENTS}{{unique_id}}/index_m1.ndx",
    run:
        import shutil
        # stuff that can be copied without being modified
        shutil.copy(input.water_gro,output.molecule1)
        shutil.copy(input.water_gro,output.molecule2)
        shutil.copy(input.select_group, output.select_group)
        shutil.copy(input.select_energy,output.select_energy)
        shutil.copy(input.select_centers,output.select_centers)
        shutil.copy(input.index_m1, output.index_m1)

        # depending on config parameters, topology and runfile will be adapted
        shutil.copy(input.water_top, output.topology)
        shutil.copy(input.base_mdp_file, output.runfile)

        # modify runfile with given parameters
        trajectory_len = find_config_parameter_value(input.config_file,"traj_len")
        integrator = find_config_parameter_value(input.config_file,"integrator")
        coupling = find_config_parameter_value(input.config_file,"coupling_constant_ps")
        step = find_config_parameter_value(input.config_file,"step_in_ps")
        dielectric_constant = find_config_parameter_value(input.config_file,"epsilon-r")
        modify_mdrun(output.runfile, "integrator", integrator)
        modify_mdrun(output.runfile,"nsteps",trajectory_len)
        modify_mdrun(output.runfile,"tau_t",coupling)
        modify_mdrun(output.runfile,"dt",step)
        modify_mdrun(output.runfile, "nstxout", "0")
        modify_mdrun(output.runfile,"nstenergy","0")
        modify_mdrun(output.runfile,"nstxout-compressed","5")
        modify_mdrun(output.runfile,"epsilon-r",dielectric_constant)
        # modify topology with given parameters
        up1_nm = find_config_parameter_value(input.config_file,"up1_nm")
        up2_nm = find_config_parameter_value(input.config_file,"up2_nm")
        force = find_config_parameter_value(input.config_file,"force")
        modify_topology(output.topology,i="1",j="4",funct=10,low=0.0,up1=up1_nm,up2=up2_nm,force_constant=force)

#
rule create_msm_gro:
    """
    Create a structure from two molecules. Expected in the folder: m1.gro, m2.gro
    """
    input:
        molecule1 = f"{PATH_EXPERIMENTS}{{unique_id}}/m1.gro",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.gro",
    output:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.gro"
    params:
        start_dist_A = 3,  # distance between centers of mass of both molecules in the combined structure
        cell_size_A = 30  # cubic box will be the output, this is size of the box in one dimension
    run:
        import MDAnalysis as mda
        from MDAnalysis import Merge
        from scipy.spatial.transform import Rotation

        central_molecule = mda.Universe(input.molecule1)
        moving_molecule = mda.Universe(input.molecule2)

        # center the both molecules
        com1 = central_molecule.atoms.center_of_mass()
        com2 = moving_molecule.atoms.center_of_mass()
        central_molecule.atoms.translate(-com1)
        moving_molecule.atoms.translate(-com2)
        # translate the second one
        moving_molecule.atoms.translate([0, 0, float(params.start_dist_A)])
        moving_molecule.atoms.rotate(Rotation.random().as_matrix(), point=moving_molecule.atoms.center_of_mass())

        # merge and write
        merged_u = Merge(central_molecule.atoms, moving_molecule.atoms)
        merged_u.dimensions = (params.cell_size_A, params.cell_size_A, params.cell_size_A, 90, 90, 90)
        with mda.Writer(output.structure) as writer:
            writer.write(merged_u)

rule run_msm_gromacs:
    """
    This rule gets structure, trajectory, topology and gromacs run file as input, as output we are only interested in
    energies.
    """
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.gro",
        runfile = f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
        topology = f"{PATH_EXPERIMENTS}{{unique_id}}/topology.top",
        select_group = f"{PATH_EXPERIMENTS}{{unique_id}}/select_group",
        select_energy = f"{PATH_EXPERIMENTS}{{unique_id}}/select_energy",
        index_m1 = f"{PATH_EXPERIMENTS}{{unique_id}}/index_m1.ndx",
        select_centers= f"{PATH_EXPERIMENTS}{{unique_id}}/select_centers",
    shadow: "shallow"
    log:
         log = "experiments/{unique_id}/logging_gromacs.log"
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/gromacs_benchmark.txt"
    output:
        energy = f"{PATH_EXPERIMENTS}{{unique_id}}/energy.xvg",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
        temp = f"{PATH_EXPERIMENTS}{{unique_id}}/temp.xtc"
    shell:
        """
        #!/bin/bash
        export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
        gmx22 grompp -f {input.runfile} -o result.tpr -c {input.structure} -p {input.topology}
        gmx22 trjconv -f {input.structure} -s result.tpr -o temp.trr < {input.select_group}
        gmx22 mdrun -s result.tpr -x {output.temp} -e ener.edr -g {log.log}
        gmx22 energy -f ener.edr -o {output.energy} < {input.select_energy}
        gmx22 trjconv -f {output.temp} -s result.tpr -pbc mol -center -o temp2.trr -n {input.index_m1} < {input.select_centers}
        gmx22 trjconv -fit rot+trans -f temp2.trr -o {output.trajectory} -s {input.structure} -n {input.index_m1} < {input.select_centers}
        """



rule run_trajectory_assignment:
    """
    A step before MSM - assign every frame of the trajectory to the corresponding cell

    As input we need the trajectory, structure and full array of the grid we wanna assign to.

    As output we get a cell index for every frame of the trajectory.
    """

    input:
        full_array = f"{PATH_OUTPUT_AUTOSAVE}{{grid_identifier}}_full_array.npy",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.gro",
        molecule2 = f"{PATH_EXPERIMENTS}{{unique_id}}/m2.gro",
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignment_benchmark.txt"
    output:
        partial_assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
    run:
        import MDAnalysis.transformations as trans

        # using all inputs
        my_grid = np.load(input.full_array)


        class AssignmentTool:
            """
            This tool is used to assign trajectory frames to grid cells.
            """

            def __init__(self, full_array: NDArray, path_structure: str, path_trajectory: str, path_reference_m2: str,
                         stop=None):
                self.full_array = full_array
                # these grids are also in A
                self.o_array, self.b_array, self.t_array = from_full_array_to_o_b_t(self.full_array)
                # whatever the format, MDAnalysis automatically converts to A
                self.trajectory_universe = mda.Universe(path_structure,path_trajectory)
                self.reference_universe = mda.Universe(path_reference_m2)
                self.second_molecule_selection = self._determine_second_molecule()
                first_molecule = self.trajectory_universe.select_atoms("not " + self.second_molecule_selection)
                self.trajectory_universe.trajectory.add_transformations(trans.translate(-first_molecule.center_of_mass()))
                self.stop = stop
                if stop is None:
                    self.stop = len(self.trajectory_universe.trajectory)

            def _determine_second_molecule(self):
                num_atoms_total = len(self.trajectory_universe.atoms)
                num_atoms_m2 = len(self.reference_universe.atoms)
                # indexing in MDAnalysis is 1-based
                # we look for indices of the second molecule
                num_atoms_m1 = num_atoms_total - num_atoms_m2
                # indices are inclusive
                return f"bynum  {num_atoms_m1 + 1}:{num_atoms_total + 1}"

            def _determine_positive_directions(self, current_universe):
                pas = current_universe.atoms.principal_axes()
                com = current_universe.atoms.center_of_mass()
                directions = [0, 0, 0]
                for atom_pos in current_universe.atoms.positions:
                    for i, pa in enumerate(pas):
                        # need to round to avoid problems - assigning direction with atoms very close to 0
                        cosalpha = np.round(pa.dot(atom_pos - com),6)
                        directions[i] = np.sign(cosalpha)
                    if not np.any(np.isclose(directions,0)):
                        break
                # if exactly one unknown use the other two and properties of righthanded systems to get third
                if np.sum(np.isclose(directions,0)) == 1:
                    # only these combinations of directions are possible in righthanded coordinate systems
                    allowed_righthanded = [[1, 1, 1], [-1, 1, -1], [1, -1, -1], [-1, -1, 1]]
                    for ar in allowed_righthanded:
                        # exactly two identical (and the third is zero)
                        if np.sum(np.isclose(ar,directions)) == 2:
                            directions = ar
                            break
                # if two (or three - that would just be an atom) unknowns raise an error
                elif np.sum(np.isclose(directions,0)) > 1:
                    raise ValueError("All atoms perpendicular to at least one of principal axes, canÂ´t determine direction.")
                return np.array(directions)

            def _complex_mdanalysis_func(self, frame_index, ag, reference_direction):
                # index the trajectory to set it to the frame_index frame
                ag.universe.trajectory[frame_index]
                return np.multiply(ag.principal_axes().T,np.tile(self._determine_positive_directions(ag) / reference_direction,(
                3, 1)))

            def _get_rotation_matrices(self):
                """
                For every frame in the trajectory, find the exact quaternion needed to go from reference structure of
                molecule2 to structure of molecule2 in this frame (this is exact if trajectory is done with rigid molecules,
                otherwise it must be an approximation).
                """
                reference_principal_axes = self.reference_universe.atoms.principal_axes().T
                inverse_pa = np.linalg.inv(reference_principal_axes)
                reference_direction = self._determine_positive_directions(self.reference_universe)
                if reference_direction is None:
                    raise ValueError("All atoms perpendicular to at least one of principal axes, can't determine direction.")
                """
                I am very sorry that this part is optimized, parallelized and completely unreadable. Rely on tests to make
                sure this stuff works and be happy that your calculations are no longer taking two days.
                """
                run_per_frame = partial(self._complex_mdanalysis_func,
                    ag=self.trajectory_universe.select_atoms(self.second_molecule_selection),
                    reference_direction=reference_direction)
                frame_values = np.arange(stop=self.stop)  #self.within_R #
                with Pool(1) as worker_pool:
                    direction_frames = worker_pool.map(run_per_frame,frame_values)
                return np.matmul(direction_frames,inverse_pa)

            def _get_quaternion_assignments(self):
                """
                Assign every perfect-fit quaternion to the closest-available quaternion from the b_grid_points.
                """
                t1 = time()
                my_quaternions = self._get_rotation_matrices()
                """
                Explanation: we have N_traj_len produkt matrices called P_i and N_quat reference matrices called R_i. The
                matrix product R_i@P_i.T describes the rotation matrix needed to get from R_i to P_i. We want the magnitude
                of this rotation to be as small as possible.

                So we calculate the matrix of magnitudes of size N_quat x N_traj_len and select the index of the smallest
                magnitude per row.

                This part of the function should be pretty fast.
                """
                reference_matrices = Rotation(self.b_array).as_matrix()
                alignment_magnitudes = np.empty((len(reference_matrices), len(my_quaternions)))
                for i, rm in enumerate(reference_matrices):
                    alignment_magnitudes[i] = Rotation.from_matrix(rm @ my_quaternions.transpose(0,2,1)).magnitude()
                result = np.argmin(alignment_magnitudes,axis=0).flatten()
                t2 = time()
                print("Q assignments time",t2 - t1)
                print(pd.DataFrame(result).describe())
                return np.array(result)

            def _get_t_assignments(self):
                """
                Given a trajectoryand an array of available radial (t-grid) points, assign each frame of the trajectory
                to the closest radial point.
                Returns:
                    an integer array as long as the trajectory, each element an index of the closest point of the radial grid
                    like [0, 0, 0, 1, 1, 1, 2 ...] (for a PT with 3 orientations)
                """
                #np.nan if np.linalg.norm(ag.center_of_mass()) > self.t_array[-1] else
                t_selection = AnalysisFromFunction(
                    lambda ag: np.argmin(np.abs(self.t_array - np.linalg.norm(np.minimum(np.mod(ag.center_of_mass(),
                        self.trajectory_universe.dimensions[:3]),
                        np.mod(-ag.center_of_mass(),self.trajectory_universe.dimensions[:3]))))),
                    self.trajectory_universe.trajectory,
                    self.trajectory_universe.select_atoms(self.second_molecule_selection))
                t_selection.run(stop=self.stop)
                t_indices = t_selection.results['timeseries'].flatten()
                print("t statistics",pd.DataFrame(t_indices).describe())
                return t_indices

            def _get_o_assignments(self):
                """
                Assign every frame of the trajectory (or PT) to the best fitting point of position grid
                Returns:
                    an array of position grid indices
                """
                # now using a normalized com and a metric on a sphere, determine which of o_grid_points is closest
                o_selection = AnalysisFromFunction(lambda ag: np.argmin(cdist(self.o_array,normalise_vectors(
                    np.minimum(np.mod(ag.center_of_mass(),self.trajectory_universe.dimensions[:3]),
                        np.mod(-ag.center_of_mass(),self.trajectory_universe.dimensions[:3])))[np.newaxis, :],
                    metric="cos"),axis=0),
                    self.trajectory_universe.trajectory,
                    self.trajectory_universe.select_atoms(self.second_molecule_selection))
                o_selection.run(stop=self.stop)
                o_indices = o_selection.results['timeseries'].flatten()
                print("o statistics",pd.DataFrame(o_indices).describe())
                return o_indices

            def _get_position_assignments(self):
                """
                Combine assigning to t_grid and o_grid.
                """
                t_assignments = self._get_t_assignments()
                o_assignments = self._get_o_assignments()
                # sum up the layer index and o index correctly
                return np.array(t_assignments * len(self.o_array) + o_assignments,dtype=float)

            def get_full_assignments(self):
                return self._get_position_assignments() * len(self.b_array) + self._get_quaternion_assignments()


        at = AssignmentTool(my_grid,input.structure,input.trajectory, input.molecule2) #, n_jobs=1
        assignments = at.get_full_assignments()
        print("NUM NANS1", np.count_nonzero(np.isnan(assignments)))

        # saving output
        np.save(output.partial_assignments,assignments)

# rule combine_trajectory_assignment:
#     """
#     A step before MSM - assign every frame of the trajectory to the corresponding cell
#
#     As input we need the trajectory, structure and full array of the grid we wanna assign to.
#
#     As output we get a cell index for every frame of the trajectory.
#     """
#     input:
#         part_assignments = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments_{{i}}.npy",i=ALL_I,  allow_missing=True)
#     output:
#         assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
#     benchmark:
#         f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/combine_assignment_benchmark.txt"
#     run:
#         print(input.part_assignments)
#         all_assignments = []
#         for one_assignment_file in input.part_assignments:
#             one_file = np.load(one_assignment_file)
#             print(one_assignment_file, one_file.shape)
#             all_assignments.append(one_file)
#         # saving output
#         all_assignments = np.concatenate(all_assignments)
#         print("SHAPE", all_assignments.shape)
#         np.save(output.assignments, all_assignments)
#
# rule combine_trajectory:
#     input:
#         part_traj= expand(f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory_slice2_{{i}}.xtc", i=ALL_I, allow_missing=True)
#     output:
#         assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory_combined.xtc",
#     shell:
#         """
#         #!/bin/bash
#         export PATH="/home/janjoswig/local/gromacs-2022/bin:$PATH"
#         echo gmx22 trjcat -f {input.part_traj} -o {output.assignments} -cat
#         gmx22 trjcat -f {input.part_traj} -o {output.assignments} -cat
#         """

# rule run_deeptime_transition_matrix:
#     """
#     A step before MSM - assign every frame of the trajectory to the corresponding cell
#
#     As input we need the trajectory, structure and full array of the grid we wanna assign to.
#
#     As output we get a cell index for every frame of the trajectory.
#     """
#
#     input:
#         trajectory = "experiments/{unique_id}/trajectory.trr",
#         structure = "experiments/{unique_id}/structure.gro",
#     wildcard_constraints:
#         grid_identifier = "deeptime.*"
#     log:
#         log = "experiments/{unique_id}/{grid_identifier}/logging_assignments.log"
#     output:
#         assignments="experiments/{unique_id}/{grid_identifier}/assignments.npy",
#     run:
#         t1 = time()
#         import MDAnalysis as mda
#         from deeptime.clustering import KMeans
#
#         estimator = KMeans(
#             n_clusters=40,# place 100 cluster centers
#             init_strategy='uniform',# uniform initialization strategy
#             max_iter=5000,# don't actually perform the optimization, just place centers
#             fixed_seed=13,
#             n_jobs=8,
#         )
#
#         trajectory_universe = mda.Universe(input.structure,input.trajectory)
#         all_positions = []
#         for ts in trajectory_universe.trajectory:
#             all_positions.extend(ts.positions[3:].flatten())
#         clustering = estimator.fit(np.array(all_positions)).fetch_model()
#         my_assignments = clustering.transform(np.array(all_positions))
#         np.save(output.assignments,my_assignments)
#         t2 = time()
#         log_the_run(wildcards.unique_id, input, output, log.log, None, t2-t1)


rule run_msm_matrix:
    """
    As input we need: assignments.

    As output we want to have the transition matrices for different taus.
    """
    input:
        assignments = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/matrix_benchmark.txt"
    output:
        transition_matrix = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/transition_matrix.npz"
    run:
        #t1 = time()
        from molgri.molecules.transitions import MSM
        from scipy import sparse

        # load data
        my_assignments = np.load(input.assignments)
        print("LOADED NUM NANS3",np.count_nonzero(np.isnan(my_assignments)))
        num_cells = int(np.nanmax(my_assignments))+1

        my_msm = MSM(assigned_trajectory=my_assignments, total_num_cells=num_cells)
        my_transition_matrices = my_msm.get_one_tau_transition_matrix(
            noncorrelated_windows=False, tau=wildcards.tau)
        # save the result
        sparse.save_npz(output.transition_matrix, my_transition_matrices)
        #t2 = time()
        #log_the_run(wildcards.unique_id, input, output, log.log, None, t2-t1)

rule run_decomposition_msm:
    """
    As output we want to have eigenvalues, eigenvectors. Es input we get a (sparse) rate matrix.
    """
    input:
        transition_matrix = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/transition_matrix.npz"
    benchmark:
        f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/decomposition_benchmark_{{sigma}}_{{which}}.txt"
    output:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_msm_{{sigma}}_{{which}}.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_msm_{{sigma}}_{{which}}.npy"
    params:
        # 1 and LR not right
        tol = 1e-5,
        maxiter = 100000
    run:
        from molgri.molecules.transitions import DecompositionTool
        from scipy import sparse

        # loading
        my_matrix = sparse.load_npz(input.transition_matrix)

        # calculation
        dt = DecompositionTool(my_matrix)
        if wildcards.sigma == "None":
            sigma = None
        else:
            sigma = float(wildcards.sigma)

        print("SIGMA", sigma, "WHICH", wildcards.which)

        all_eigenval, all_eigenvec = dt.get_decomposition(tol=params.tol, maxiter=params.maxiter,
            which=wildcards.which,
            sigma=sigma)

        # saving to file
        print("")
        np.save(output.eigenvalues, np.array(all_eigenval))
        np.save(output.eigenvectors, np.array(all_eigenvec))

rule correct_msm_eigenvectors:
    """
    Select only the ones that are not exchanges with boundary
    """
    input:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_msm_{{sigma}}_{{which}}.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_msm_{{sigma}}_{{which}}.npy"
    output:
        corr_eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_correctedmsm_{{sigma}}_{{which}}.npy",
        corr_eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_correctedmsm_{{sigma}}_{{which}}.npy"
    run:
        import numpy as np
        original_eigenvalues = np.load(input.eigenvalues)
        original_eigenvectors = np.load(input.eigenvectors)

        corrected_eigenvalues = []
        corrected_eigenvectors = []
        for one_orig_eigenvalue, one_orig_eigenvec in zip(original_eigenvalues, original_eigenvectors.T):
            eigenvec_len = len(one_orig_eigenvec)
            magnitude_eigenvec = np.abs(one_orig_eigenvec)
            # correct eigenvectors are the ones where over 70% of the total absolute value is in the middle third
            success = np.sum(magnitude_eigenvec[
                             int(eigenvec_len / 3):int(2 * eigenvec_len / 3)]) > 0.8 * np.sum(magnitude_eigenvec)
            print(np.sum(magnitude_eigenvec[
                         int(eigenvec_len / 3):int(2 * eigenvec_len / 3)]),0.8 * np.sum(magnitude_eigenvec))
            if success:
                corrected_eigenvalues.append(one_orig_eigenvalue)
                corrected_eigenvectors.append(one_orig_eigenvec)
        np.save(output.corr_eigenvalues, np.array(corrected_eigenvalues))
        np.save(output.corr_eigenvectors,np.array(corrected_eigenvectors).T)


rule run_plot_everything_msm:
    """
    Some stuff to plot after a MSM calculation: eigenvalues, ITS, eigenvectors
    """
    input:
        eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.npy",
        eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}.npy",
    output:
        plot_eigenvectors = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}.png",
        plot_eigenvalues = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.png",
    run:
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=input.eigenvectors,
            tau_array=None)
        # eigenvectors
        pt.plot_eigenvectors_flat(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvectors, height=1200)
        # eigenvalues
        pt.plot_eigenvalues(index_tau=wildcards.tau)
        pt.save_to(output.plot_eigenvalues)

rule run_plot_its_msm:
    input:
        eigenvalues = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.npy",
            tau=TAUS, allow_missing=True),
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    output:
        plot_its = report(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/its_{{is_corrected}}_{{sigma}}_{{which}}.png",
        category="MSM")
    run:
        writeout = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        timesteps = float(read_from_mdrun(input.runfile,"dt"))
        from molgri.plotting.transition_plots import PlotlyTransitions
        pt = PlotlyTransitions(is_msm=True, path_eigenvalues=input.eigenvalues, path_eigenvectors=None,
            tau_array=TAUS)
        print(" ")
        pt.plot_its_msm(writeout=writeout, time_step_ps=timesteps)
        pt.save_to(output.plot_its)


rule compile_vmd_log:
    """
    Input are the saved eigenvectors. Output = a vmd log that can be used later with:

    vmd <gro file> <xtc file>
    play <vmdlog file>
    """
    input:
        structure = f"{PATH_EXPERIMENTS}{{unique_id}}/structure.gro",
        trajectory = f"{PATH_EXPERIMENTS}{{unique_id}}/trajectory.xtc",
        eigenvectors=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}.npy",
        assignments=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/assignments.npy",
        # in the script only the numbers for frames need to be changed.
        script="molgri/scripts/vmd_show_eigenvectors_ar"
    output:
        vmdlog=f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvectors_{{is_corrected}}_{{sigma}}_{{which}}_vmdlog_msm",
        fig_tga = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}_{{sigma}}_{{which}}_{{is_corrected}}.tga", i=[0, 1, 2, 3, 4], allow_missing=True),
        fig_png= report(expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvector_{{i}}_{{sigma}}_{{which}}_{{is_corrected}}.png",i=[0, 1, 2, 3, 4], allow_missing=True),
        category="{unique_id}")
    params:
        num_extremes=30,
        num_eigenvec=5  # only show the first num_eigenvec
    run:
        from molgri.plotting.create_vmdlog import show_eigenvectors_MSM

        print(output.fig_tga)

        eigenvectors = np.load(input.eigenvectors)

        show_eigenvectors_MSM(input.script, output.vmdlog, input.assignments, eigenvector_array=eigenvectors,num_eigenvec=params.num_eigenvec,
            num_extremes=params.num_extremes, figure_paths=output.fig_tga)
        print("created otput.vmd")
        shell("vmd {input.structure} {input.trajectory} < {output.vmdlog}")
        print("created tga")
        for el_tga, el_png in zip(output.fig_tga, output.fig_png):
            shell("convert {el_tga} {el_png}")


rule print_its:
    input:
        eigenvalues = expand(f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/eigenvalues_{{is_corrected}}_{{sigma}}_{{which}}.npy",
            sigma="None", which="LR", is_corrected=["msm"],allow_missing=True),
        runfile= f"{PATH_EXPERIMENTS}{{unique_id}}/mdrun.mdp",
    output:
        data = f"{PATH_EXPERIMENTS}{{unique_id}}/{{grid_identifier}}/{{tau}}/its.csv"
    run:
        import pandas as pd

        try:
            writeout = int(read_from_mdrun(input.runfile,"nstxout-compressed"))
        except TypeError:
            writeout = int(read_from_mdrun(input.runfile,"nstxout"))
        timesteps = float(read_from_mdrun(input.runfile,"dt"))

        all_its = []
        for one_eigenvalues_file in input.eigenvalues:
            eigenvals = np.load(one_eigenvalues_file)[1:]  # dropping the first one as it should be zero and cause issues
            all_its.append(-1*  np.array(int(wildcards.tau) * writeout * timesteps / np.log(np.abs(eigenvals))))
        my_df = pd.DataFrame(all_its, columns=[f"ITS {i} [ps]" for i in range(1, len(all_its[0])+1)])
        my_df.to_csv(output.data)
